import { MessageList } from './chunk-AY6DBRS3.js';
import { TABLE_SCHEMAS, TABLE_SCORERS, listTracesArgsSchema, toTraceSpans, TABLE_WORKFLOW_SNAPSHOT } from './chunk-PS5ONCXY.js';
import { deepEqual } from './chunk-AXHBJ4GX.js';
import { MastraError } from './chunk-FJEVLHJT.js';
import { MastraBase } from './chunk-WCAFTXGK.js';
import { jsonSchemaToZod } from '@mastra/schema-compat/json-to-zod';
import { z } from 'zod';

// src/storage/base.ts
function normalizePerPage(perPageInput, defaultValue) {
  if (perPageInput === false) {
    return Number.MAX_SAFE_INTEGER;
  } else if (perPageInput === 0) {
    return 0;
  } else if (typeof perPageInput === "number" && perPageInput > 0) {
    return perPageInput;
  } else if (typeof perPageInput === "number" && perPageInput < 0) {
    throw new Error("perPage must be >= 0");
  }
  return defaultValue;
}
function calculatePagination(page, perPageInput, normalizedPerPage) {
  return {
    offset: perPageInput === false ? 0 : page * normalizedPerPage,
    perPage: perPageInput === false ? false : normalizedPerPage
  };
}
var MastraCompositeStore = class extends MastraBase {
  hasInitialized = null;
  shouldCacheInit = true;
  id;
  stores;
  /**
   * When true, automatic initialization (table creation/migrations) is disabled.
   */
  disableInit = false;
  constructor(config) {
    const name = config.name ?? "MastraCompositeStore";
    if (!config.id || typeof config.id !== "string" || config.id.trim() === "") {
      throw new Error(`${name}: id must be provided and cannot be empty.`);
    }
    super({
      component: "STORAGE",
      name
    });
    this.id = config.id;
    this.disableInit = config.disableInit ?? false;
    if (config.default || config.domains) {
      const defaultStores = config.default?.stores;
      const domainOverrides = config.domains ?? {};
      const hasDefaultDomains = defaultStores && Object.values(defaultStores).some((v) => v !== void 0);
      const hasOverrideDomains = Object.values(domainOverrides).some((v) => v !== void 0);
      if (!hasDefaultDomains && !hasOverrideDomains) {
        throw new Error(
          "MastraCompositeStore requires at least one storage source. Provide either a default storage with domains or domain overrides."
        );
      }
      this.stores = {
        memory: domainOverrides.memory ?? defaultStores?.memory,
        workflows: domainOverrides.workflows ?? defaultStores?.workflows,
        scores: domainOverrides.scores ?? defaultStores?.scores,
        observability: domainOverrides.observability ?? defaultStores?.observability,
        agents: domainOverrides.agents ?? defaultStores?.agents,
        datasets: domainOverrides.datasets ?? defaultStores?.datasets,
        experiments: domainOverrides.experiments ?? defaultStores?.experiments,
        promptBlocks: domainOverrides.promptBlocks ?? defaultStores?.promptBlocks,
        scorerDefinitions: domainOverrides.scorerDefinitions ?? defaultStores?.scorerDefinitions,
        mcpClients: domainOverrides.mcpClients ?? defaultStores?.mcpClients
      };
    }
  }
  /**
   * Get a domain-specific storage interface.
   *
   * @param storeName - The name of the domain to access ('memory', 'workflows', 'scores', 'observability', 'agents')
   * @returns The domain storage interface, or undefined if not available
   *
   * @example
   * ```typescript
   * const memory = await storage.getStore('memory');
   * if (memory) {
   *   await memory.saveThread({ thread });
   * }
   * ```
   */
  async getStore(storeName) {
    return this.stores?.[storeName];
  }
  /**
   * Initialize all domain stores.
   * This creates necessary tables, indexes, and performs any required migrations.
   */
  async init() {
    if (this.shouldCacheInit && await this.hasInitialized) {
      return;
    }
    const initTasks = [];
    if (this.stores?.memory) {
      initTasks.push(this.stores.memory.init());
    }
    if (this.stores?.workflows) {
      initTasks.push(this.stores.workflows.init());
    }
    if (this.stores?.scores) {
      initTasks.push(this.stores.scores.init());
    }
    if (this.stores?.observability) {
      initTasks.push(this.stores.observability.init());
    }
    if (this.stores?.agents) {
      initTasks.push(this.stores.agents.init());
    }
    if (this.stores?.datasets) {
      initTasks.push(this.stores.datasets.init());
    }
    if (this.stores?.experiments) {
      initTasks.push(this.stores.experiments.init());
    }
    if (this.stores?.promptBlocks) {
      initTasks.push(this.stores.promptBlocks.init());
    }
    if (this.stores?.scorerDefinitions) {
      initTasks.push(this.stores.scorerDefinitions.init());
    }
    if (this.stores?.mcpClients) {
      initTasks.push(this.stores.mcpClients.init());
    }
    this.hasInitialized = Promise.all(initTasks).then(() => true);
    await this.hasInitialized;
  }
};
var MastraStorage = class extends MastraCompositeStore {
};

// src/storage/domains/base.ts
var StorageDomain = class extends MastraBase {
  /**
   * Initialize the storage domain.
   * This should create any necessary tables/collections.
   * Default implementation is a no-op - override in adapters that need initialization.
   */
  async init() {
  }
};

// src/storage/domains/versioned.ts
var ENTITY_ORDER_BY_SET = {
  createdAt: true,
  updatedAt: true
};
var SORT_DIRECTION_SET = {
  ASC: true,
  DESC: true
};
var VERSION_ORDER_BY_SET = {
  versionNumber: true,
  createdAt: true
};
var VersionedStorageDomain = class extends StorageDomain {
  // ==========================================================================
  // Concrete resolution methods
  // ==========================================================================
  /**
   * Strips version metadata fields from a version row, leaving only snapshot config fields.
   */
  extractSnapshotConfig(version) {
    const result = {};
    const metadataSet = new Set(this.versionMetadataFields);
    for (const [key, value] of Object.entries(version)) {
      if (!metadataSet.has(key)) {
        result[key] = value;
      }
    }
    return result;
  }
  /**
   * Resolves an entity by merging its thin record with the active (or latest) version config.
   */
  async getByIdResolved(id) {
    const entity = await this.getById(id);
    if (!entity) {
      return null;
    }
    return this.resolveEntity(entity);
  }
  /**
   * Lists entities with version resolution.
   */
  async listResolved(args) {
    const result = await this.list(args);
    const entities = result[this.listKey];
    const resolved = await Promise.all(entities.map((entity) => this.resolveEntity(entity)));
    return {
      ...result,
      [this.listKey]: resolved
    };
  }
  /**
   * Resolves a single entity by merging it with its active or latest version.
   */
  async resolveEntity(entity) {
    let version = null;
    if (entity.activeVersionId) {
      version = await this.getVersion(entity.activeVersionId);
      if (!version) {
        this.logger?.warn?.(
          `Entity ${entity.id} has activeVersionId ${entity.activeVersionId} but version not found. Falling back to latest version.`
        );
      }
    }
    if (!version) {
      version = await this.getLatestVersion(entity.id);
    }
    if (version) {
      const snapshotConfig = this.extractSnapshotConfig(version);
      return {
        ...entity,
        ...snapshotConfig
      };
    }
    return entity;
  }
  // ==========================================================================
  // Protected Helper Methods
  // ==========================================================================
  parseOrderBy(orderBy, defaultDirection = "DESC") {
    return {
      field: orderBy?.field && orderBy.field in ENTITY_ORDER_BY_SET ? orderBy.field : "createdAt",
      direction: orderBy?.direction && orderBy.direction in SORT_DIRECTION_SET ? orderBy.direction : defaultDirection
    };
  }
  parseVersionOrderBy(orderBy, defaultDirection = "DESC") {
    return {
      field: orderBy?.field && orderBy.field in VERSION_ORDER_BY_SET ? orderBy.field : "versionNumber",
      direction: orderBy?.direction && orderBy.direction in SORT_DIRECTION_SET ? orderBy.direction : defaultDirection
    };
  }
};

// src/storage/domains/agents/base.ts
var AgentsStorage = class extends VersionedStorageDomain {
  listKey = "agents";
  versionMetadataFields = [
    "id",
    "agentId",
    "versionNumber",
    "changedFields",
    "changeMessage",
    "createdAt"
  ];
  constructor() {
    super({
      component: "STORAGE",
      name: "AGENTS"
    });
  }
};

// src/storage/domains/agents/inmemory.ts
var InMemoryAgentsStorage = class extends AgentsStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.agents.clear();
    this.db.agentVersions.clear();
  }
  // ==========================================================================
  // Agent CRUD Methods
  // ==========================================================================
  async getById(id) {
    this.logger.debug(`InMemoryAgentsStorage: getById called for ${id}`);
    const agent = this.db.agents.get(id);
    return agent ? this.deepCopyAgent(agent) : null;
  }
  async create(input) {
    const { agent } = input;
    this.logger.debug(`InMemoryAgentsStorage: create called for ${agent.id}`);
    if (this.db.agents.has(agent.id)) {
      throw new Error(`Agent with id ${agent.id} already exists`);
    }
    const now = /* @__PURE__ */ new Date();
    const newAgent = {
      id: agent.id,
      status: "draft",
      activeVersionId: void 0,
      authorId: agent.authorId,
      metadata: agent.metadata,
      createdAt: now,
      updatedAt: now
    };
    this.db.agents.set(agent.id, newAgent);
    const { id: _id, authorId: _authorId, metadata: _metadata, ...snapshotConfig } = agent;
    const versionId = crypto.randomUUID();
    await this.createVersion({
      id: versionId,
      agentId: agent.id,
      versionNumber: 1,
      ...snapshotConfig,
      changedFields: Object.keys(snapshotConfig),
      changeMessage: "Initial version"
    });
    return this.deepCopyAgent(newAgent);
  }
  async update(input) {
    const { id, ...updates } = input;
    this.logger.debug(`InMemoryAgentsStorage: update called for ${id}`);
    const existingAgent = this.db.agents.get(id);
    if (!existingAgent) {
      throw new Error(`Agent with id ${id} not found`);
    }
    const { authorId, activeVersionId, metadata, ...configFields } = updates;
    const configFieldNames = [
      "name",
      "description",
      "instructions",
      "model",
      "tools",
      "defaultOptions",
      "workflows",
      "agents",
      "integrationTools",
      "inputProcessors",
      "outputProcessors",
      "memory",
      "scorers",
      "mcpClients",
      "requestContextSchema"
    ];
    const hasConfigUpdate = configFieldNames.some((field) => field in configFields);
    const updatedAgent = {
      ...existingAgent,
      ...authorId !== void 0 && { authorId },
      ...activeVersionId !== void 0 && { activeVersionId },
      ...metadata !== void 0 && {
        metadata: { ...existingAgent.metadata, ...metadata }
      },
      updatedAt: /* @__PURE__ */ new Date()
    };
    if (activeVersionId !== void 0) {
      updatedAgent.status = "published";
    }
    if (hasConfigUpdate) {
      const latestVersion = await this.getLatestVersion(id);
      if (!latestVersion) {
        throw new Error(`No versions found for agent ${id}`);
      }
      const {
        id: _versionId,
        agentId: _agentId,
        versionNumber: _versionNumber,
        changedFields: _changedFields,
        changeMessage: _changeMessage,
        createdAt: _createdAt,
        ...latestConfig
      } = latestVersion;
      const sanitizedConfigFields = Object.fromEntries(
        Object.entries(configFields).map(([key, value]) => [key, value === null ? void 0 : value])
      );
      const newConfig = {
        ...latestConfig,
        ...sanitizedConfigFields
      };
      const changedFields = configFieldNames.filter(
        (field) => field in configFields && JSON.stringify(configFields[field]) !== JSON.stringify(latestConfig[field])
      );
      if (changedFields.length > 0) {
        const newVersionId = crypto.randomUUID();
        const newVersionNumber = latestVersion.versionNumber + 1;
        await this.createVersion({
          id: newVersionId,
          agentId: id,
          versionNumber: newVersionNumber,
          ...newConfig,
          changedFields,
          changeMessage: `Updated ${changedFields.join(", ")}`
        });
      }
    }
    this.db.agents.set(id, updatedAgent);
    return this.deepCopyAgent(updatedAgent);
  }
  async delete(id) {
    this.logger.debug(`InMemoryAgentsStorage: delete called for ${id}`);
    this.db.agents.delete(id);
    await this.deleteVersionsByParentId(id);
  }
  async list(args) {
    const { page = 0, perPage: perPageInput, orderBy, authorId, metadata } = args || {};
    const { field, direction } = this.parseOrderBy(orderBy);
    this.logger.debug(`InMemoryAgentsStorage: list called`);
    const perPage = normalizePerPage(perPageInput, 100);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    let agents = Array.from(this.db.agents.values());
    if (authorId !== void 0) {
      agents = agents.filter((agent) => agent.authorId === authorId);
    }
    if (metadata && Object.keys(metadata).length > 0) {
      agents = agents.filter((agent) => {
        if (!agent.metadata) return false;
        return Object.entries(metadata).every(([key, value]) => deepEqual(agent.metadata[key], value));
      });
    }
    const sortedAgents = this.sortAgents(agents, field, direction);
    const clonedAgents = sortedAgents.map((agent) => this.deepCopyAgent(agent));
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    return {
      agents: clonedAgents.slice(offset, offset + perPage),
      total: clonedAgents.length,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < clonedAgents.length
    };
  }
  // ==========================================================================
  // Agent Version Methods
  // ==========================================================================
  async createVersion(input) {
    this.logger.debug(`InMemoryAgentsStorage: createVersion called for agent ${input.agentId}`);
    if (this.db.agentVersions.has(input.id)) {
      throw new Error(`Version with id ${input.id} already exists`);
    }
    for (const version2 of this.db.agentVersions.values()) {
      if (version2.agentId === input.agentId && version2.versionNumber === input.versionNumber) {
        throw new Error(`Version number ${input.versionNumber} already exists for agent ${input.agentId}`);
      }
    }
    const version = {
      ...input,
      createdAt: /* @__PURE__ */ new Date()
    };
    this.db.agentVersions.set(input.id, this.deepCopyVersion(version));
    return this.deepCopyVersion(version);
  }
  async getVersion(id) {
    this.logger.debug(`InMemoryAgentsStorage: getVersion called for ${id}`);
    const version = this.db.agentVersions.get(id);
    return version ? this.deepCopyVersion(version) : null;
  }
  async getVersionByNumber(agentId, versionNumber) {
    this.logger.debug(`InMemoryAgentsStorage: getVersionByNumber called for agent ${agentId}, v${versionNumber}`);
    for (const version of this.db.agentVersions.values()) {
      if (version.agentId === agentId && version.versionNumber === versionNumber) {
        return this.deepCopyVersion(version);
      }
    }
    return null;
  }
  async getLatestVersion(agentId) {
    this.logger.debug(`InMemoryAgentsStorage: getLatestVersion called for agent ${agentId}`);
    let latest = null;
    for (const version of this.db.agentVersions.values()) {
      if (version.agentId === agentId) {
        if (!latest || version.versionNumber > latest.versionNumber) {
          latest = version;
        }
      }
    }
    return latest ? this.deepCopyVersion(latest) : null;
  }
  async listVersions(input) {
    const { agentId, page = 0, perPage: perPageInput, orderBy } = input;
    const { field, direction } = this.parseVersionOrderBy(orderBy);
    this.logger.debug(`InMemoryAgentsStorage: listVersions called for agent ${agentId}`);
    const perPage = normalizePerPage(perPageInput, 20);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    let versions = Array.from(this.db.agentVersions.values()).filter((v) => v.agentId === agentId);
    versions = this.sortVersions(versions, field, direction);
    const clonedVersions = versions.map((v) => this.deepCopyVersion(v));
    const total = clonedVersions.length;
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const paginatedVersions = clonedVersions.slice(offset, offset + perPage);
    return {
      versions: paginatedVersions,
      total,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < total
    };
  }
  async deleteVersion(id) {
    this.logger.debug(`InMemoryAgentsStorage: deleteVersion called for ${id}`);
    this.db.agentVersions.delete(id);
  }
  async deleteVersionsByParentId(entityId) {
    this.logger.debug(`InMemoryAgentsStorage: deleteVersionsByParentId called for agent ${entityId}`);
    const idsToDelete = [];
    for (const [id, version] of this.db.agentVersions.entries()) {
      if (version.agentId === entityId) {
        idsToDelete.push(id);
      }
    }
    for (const id of idsToDelete) {
      this.db.agentVersions.delete(id);
    }
  }
  async countVersions(agentId) {
    this.logger.debug(`InMemoryAgentsStorage: countVersions called for agent ${agentId}`);
    let count = 0;
    for (const version of this.db.agentVersions.values()) {
      if (version.agentId === agentId) {
        count++;
      }
    }
    return count;
  }
  // ==========================================================================
  // Private Helper Methods
  // ==========================================================================
  /**
   * Deep copy a thin agent record to prevent external mutation of stored data
   */
  deepCopyAgent(agent) {
    return {
      ...agent,
      metadata: agent.metadata ? { ...agent.metadata } : agent.metadata
    };
  }
  /**
   * Deep copy a version to prevent external mutation of stored data
   */
  deepCopyVersion(version) {
    return structuredClone(version);
  }
  sortAgents(agents, field, direction) {
    return agents.sort((a, b) => {
      const aValue = new Date(a[field]).getTime();
      const bValue = new Date(b[field]).getTime();
      return direction === "ASC" ? aValue - bValue : bValue - aValue;
    });
  }
  sortVersions(versions, field, direction) {
    return versions.sort((a, b) => {
      let aVal;
      let bVal;
      if (field === "createdAt") {
        aVal = a.createdAt.getTime();
        bVal = b.createdAt.getTime();
      } else {
        aVal = a.versionNumber;
        bVal = b.versionNumber;
      }
      return direction === "ASC" ? aVal - bVal : bVal - aVal;
    });
  }
};

// src/storage/domains/inmemory-db.ts
var InMemoryDB = class {
  threads = /* @__PURE__ */ new Map();
  messages = /* @__PURE__ */ new Map();
  resources = /* @__PURE__ */ new Map();
  workflows = /* @__PURE__ */ new Map();
  scores = /* @__PURE__ */ new Map();
  traces = /* @__PURE__ */ new Map();
  agents = /* @__PURE__ */ new Map();
  agentVersions = /* @__PURE__ */ new Map();
  promptBlocks = /* @__PURE__ */ new Map();
  promptBlockVersions = /* @__PURE__ */ new Map();
  scorerDefinitions = /* @__PURE__ */ new Map();
  scorerDefinitionVersions = /* @__PURE__ */ new Map();
  mcpClients = /* @__PURE__ */ new Map();
  mcpClientVersions = /* @__PURE__ */ new Map();
  /** Observational memory records, keyed by resourceId, each holding array of records (generations) */
  observationalMemory = /* @__PURE__ */ new Map();
  // Dataset domain maps
  datasets = /* @__PURE__ */ new Map();
  datasetItems = /* @__PURE__ */ new Map();
  datasetVersions = /* @__PURE__ */ new Map();
  // Experiment domain maps
  experiments = /* @__PURE__ */ new Map();
  experimentResults = /* @__PURE__ */ new Map();
  /**
   * Clears all data from all collections.
   * Useful for testing.
   */
  clear() {
    this.threads.clear();
    this.messages.clear();
    this.resources.clear();
    this.workflows.clear();
    this.scores.clear();
    this.traces.clear();
    this.agents.clear();
    this.agentVersions.clear();
    this.promptBlocks.clear();
    this.promptBlockVersions.clear();
    this.scorerDefinitions.clear();
    this.scorerDefinitionVersions.clear();
    this.mcpClients.clear();
    this.mcpClientVersions.clear();
    this.observationalMemory.clear();
    this.datasets.clear();
    this.datasetItems.clear();
    this.datasetVersions.clear();
    this.experiments.clear();
    this.experimentResults.clear();
  }
};

// src/storage/domains/mcp-clients/base.ts
var MCPClientsStorage = class extends VersionedStorageDomain {
  listKey = "mcpClients";
  versionMetadataFields = [
    "id",
    "mcpClientId",
    "versionNumber",
    "changedFields",
    "changeMessage",
    "createdAt"
  ];
  constructor() {
    super({
      component: "STORAGE",
      name: "MCP_CLIENTS"
    });
  }
};

// src/storage/domains/mcp-clients/inmemory.ts
var InMemoryMCPClientsStorage = class extends MCPClientsStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.mcpClients.clear();
    this.db.mcpClientVersions.clear();
  }
  // ==========================================================================
  // MCP Client CRUD Methods
  // ==========================================================================
  async getById(id) {
    this.logger.debug(`InMemoryMCPClientsStorage: getById called for ${id}`);
    const config = this.db.mcpClients.get(id);
    return config ? this.deepCopyConfig(config) : null;
  }
  async create(input) {
    const { mcpClient } = input;
    this.logger.debug(`InMemoryMCPClientsStorage: create called for ${mcpClient.id}`);
    if (this.db.mcpClients.has(mcpClient.id)) {
      throw new Error(`MCP client with id ${mcpClient.id} already exists`);
    }
    const now = /* @__PURE__ */ new Date();
    const newConfig = {
      id: mcpClient.id,
      status: "draft",
      activeVersionId: void 0,
      authorId: mcpClient.authorId,
      metadata: mcpClient.metadata,
      createdAt: now,
      updatedAt: now
    };
    this.db.mcpClients.set(mcpClient.id, newConfig);
    const { id: _id, authorId: _authorId, metadata: _metadata, ...snapshotConfig } = mcpClient;
    const versionId = crypto.randomUUID();
    await this.createVersion({
      id: versionId,
      mcpClientId: mcpClient.id,
      versionNumber: 1,
      ...snapshotConfig,
      changedFields: Object.keys(snapshotConfig),
      changeMessage: "Initial version"
    });
    return this.deepCopyConfig(newConfig);
  }
  async update(input) {
    const { id, ...updates } = input;
    this.logger.debug(`InMemoryMCPClientsStorage: update called for ${id}`);
    const existingConfig = this.db.mcpClients.get(id);
    if (!existingConfig) {
      throw new Error(`MCP client with id ${id} not found`);
    }
    const { authorId, activeVersionId, metadata, status, ...configFields } = updates;
    const configFieldNames = ["name", "description", "servers"];
    const hasConfigUpdate = configFieldNames.some((field) => field in configFields);
    const updatedConfig = {
      ...existingConfig,
      ...authorId !== void 0 && { authorId },
      ...activeVersionId !== void 0 && { activeVersionId },
      ...status !== void 0 && { status },
      ...metadata !== void 0 && {
        metadata: { ...existingConfig.metadata, ...metadata }
      },
      updatedAt: /* @__PURE__ */ new Date()
    };
    if (activeVersionId !== void 0 && status === void 0) {
      updatedConfig.status = "published";
    }
    if (hasConfigUpdate) {
      const latestVersion = await this.getLatestVersion(id);
      if (!latestVersion) {
        throw new Error(`No versions found for MCP client ${id}`);
      }
      const {
        id: _versionId,
        mcpClientId: _mcpClientId,
        versionNumber: _versionNumber,
        changedFields: _changedFields,
        changeMessage: _changeMessage,
        createdAt: _createdAt,
        ...latestConfig
      } = latestVersion;
      const newConfig = {
        ...latestConfig,
        ...configFields
      };
      const changedFields = configFieldNames.filter(
        (field) => field in configFields && JSON.stringify(configFields[field]) !== JSON.stringify(latestConfig[field])
      );
      if (changedFields.length > 0) {
        const newVersionId = crypto.randomUUID();
        const newVersionNumber = latestVersion.versionNumber + 1;
        await this.createVersion({
          id: newVersionId,
          mcpClientId: id,
          versionNumber: newVersionNumber,
          ...newConfig,
          changedFields,
          changeMessage: `Updated ${changedFields.join(", ")}`
        });
      }
    }
    this.db.mcpClients.set(id, updatedConfig);
    return this.deepCopyConfig(updatedConfig);
  }
  async delete(id) {
    this.logger.debug(`InMemoryMCPClientsStorage: delete called for ${id}`);
    this.db.mcpClients.delete(id);
    await this.deleteVersionsByParentId(id);
  }
  async list(args) {
    const { page = 0, perPage: perPageInput, orderBy, authorId, metadata } = args || {};
    const { field, direction } = this.parseOrderBy(orderBy);
    this.logger.debug(`InMemoryMCPClientsStorage: list called`);
    const perPage = normalizePerPage(perPageInput, 100);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    let configs = Array.from(this.db.mcpClients.values());
    if (authorId !== void 0) {
      configs = configs.filter((config) => config.authorId === authorId);
    }
    if (metadata && Object.keys(metadata).length > 0) {
      configs = configs.filter((config) => {
        if (!config.metadata) return false;
        return Object.entries(metadata).every(([key, value]) => deepEqual(config.metadata[key], value));
      });
    }
    const sortedConfigs = this.sortConfigs(configs, field, direction);
    const clonedConfigs = sortedConfigs.map((config) => this.deepCopyConfig(config));
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    return {
      mcpClients: clonedConfigs.slice(offset, offset + perPage),
      total: clonedConfigs.length,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < clonedConfigs.length
    };
  }
  // ==========================================================================
  // MCP Client Version Methods
  // ==========================================================================
  async createVersion(input) {
    this.logger.debug(`InMemoryMCPClientsStorage: createVersion called for MCP client ${input.mcpClientId}`);
    if (this.db.mcpClientVersions.has(input.id)) {
      throw new Error(`Version with id ${input.id} already exists`);
    }
    for (const version2 of this.db.mcpClientVersions.values()) {
      if (version2.mcpClientId === input.mcpClientId && version2.versionNumber === input.versionNumber) {
        throw new Error(`Version number ${input.versionNumber} already exists for MCP client ${input.mcpClientId}`);
      }
    }
    const version = {
      ...input,
      createdAt: /* @__PURE__ */ new Date()
    };
    this.db.mcpClientVersions.set(input.id, this.deepCopyVersion(version));
    return this.deepCopyVersion(version);
  }
  async getVersion(id) {
    this.logger.debug(`InMemoryMCPClientsStorage: getVersion called for ${id}`);
    const version = this.db.mcpClientVersions.get(id);
    return version ? this.deepCopyVersion(version) : null;
  }
  async getVersionByNumber(mcpClientId, versionNumber) {
    this.logger.debug(
      `InMemoryMCPClientsStorage: getVersionByNumber called for MCP client ${mcpClientId}, v${versionNumber}`
    );
    for (const version of this.db.mcpClientVersions.values()) {
      if (version.mcpClientId === mcpClientId && version.versionNumber === versionNumber) {
        return this.deepCopyVersion(version);
      }
    }
    return null;
  }
  async getLatestVersion(mcpClientId) {
    this.logger.debug(`InMemoryMCPClientsStorage: getLatestVersion called for MCP client ${mcpClientId}`);
    let latest = null;
    for (const version of this.db.mcpClientVersions.values()) {
      if (version.mcpClientId === mcpClientId) {
        if (!latest || version.versionNumber > latest.versionNumber) {
          latest = version;
        }
      }
    }
    return latest ? this.deepCopyVersion(latest) : null;
  }
  async listVersions(input) {
    const { mcpClientId, page = 0, perPage: perPageInput, orderBy } = input;
    const { field, direction } = this.parseVersionOrderBy(orderBy);
    this.logger.debug(`InMemoryMCPClientsStorage: listVersions called for MCP client ${mcpClientId}`);
    const perPage = normalizePerPage(perPageInput, 20);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    let versions = Array.from(this.db.mcpClientVersions.values()).filter((v) => v.mcpClientId === mcpClientId);
    versions = this.sortVersions(versions, field, direction);
    const clonedVersions = versions.map((v) => this.deepCopyVersion(v));
    const total = clonedVersions.length;
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const paginatedVersions = clonedVersions.slice(offset, offset + perPage);
    return {
      versions: paginatedVersions,
      total,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < total
    };
  }
  async deleteVersion(id) {
    this.logger.debug(`InMemoryMCPClientsStorage: deleteVersion called for ${id}`);
    this.db.mcpClientVersions.delete(id);
  }
  async deleteVersionsByParentId(entityId) {
    this.logger.debug(`InMemoryMCPClientsStorage: deleteVersionsByParentId called for MCP client ${entityId}`);
    const idsToDelete = [];
    for (const [id, version] of this.db.mcpClientVersions.entries()) {
      if (version.mcpClientId === entityId) {
        idsToDelete.push(id);
      }
    }
    for (const id of idsToDelete) {
      this.db.mcpClientVersions.delete(id);
    }
  }
  async countVersions(mcpClientId) {
    this.logger.debug(`InMemoryMCPClientsStorage: countVersions called for MCP client ${mcpClientId}`);
    let count = 0;
    for (const version of this.db.mcpClientVersions.values()) {
      if (version.mcpClientId === mcpClientId) {
        count++;
      }
    }
    return count;
  }
  // ==========================================================================
  // Private Helper Methods
  // ==========================================================================
  deepCopyConfig(config) {
    return {
      ...config,
      metadata: config.metadata ? { ...config.metadata } : config.metadata
    };
  }
  deepCopyVersion(version) {
    return {
      ...version,
      servers: version.servers ? JSON.parse(JSON.stringify(version.servers)) : version.servers,
      changedFields: version.changedFields ? [...version.changedFields] : version.changedFields
    };
  }
  sortConfigs(configs, field, direction) {
    return configs.sort((a, b) => {
      const aValue = a[field].getTime();
      const bValue = b[field].getTime();
      return direction === "ASC" ? aValue - bValue : bValue - aValue;
    });
  }
  sortVersions(versions, field, direction) {
    return versions.sort((a, b) => {
      let aVal;
      let bVal;
      if (field === "createdAt") {
        aVal = a.createdAt.getTime();
        bVal = b.createdAt.getTime();
      } else {
        aVal = a.versionNumber;
        bVal = b.versionNumber;
      }
      return direction === "ASC" ? aVal - bVal : bVal - aVal;
    });
  }
};

// src/storage/utils.ts
function safelyParseJSON(input) {
  if (input && typeof input === "object") return input;
  if (input == null) return {};
  if (typeof input === "string") {
    try {
      return JSON.parse(input);
    } catch {
      return input;
    }
  }
  return {};
}
function transformRow(row, tableName, options = {}) {
  const { preferredTimestampFields = {}, convertTimestamps = false, nullValuePattern, fieldMappings = {} } = options;
  const tableSchema = TABLE_SCHEMAS[tableName];
  const result = {};
  for (const [key, columnSchema] of Object.entries(tableSchema)) {
    const sourceKey = fieldMappings[key] ?? key;
    let value = row[sourceKey];
    if (preferredTimestampFields[key]) {
      value = row[preferredTimestampFields[key]] ?? value;
    }
    if (value === void 0 || value === null) {
      continue;
    }
    if (nullValuePattern && value === nullValuePattern) {
      continue;
    }
    if (columnSchema.type === "jsonb") {
      if (typeof value === "string") {
        result[key] = safelyParseJSON(value);
      } else if (typeof value === "object") {
        result[key] = value;
      } else {
        result[key] = value;
      }
    } else if (columnSchema.type === "timestamp" && convertTimestamps && typeof value === "string") {
      result[key] = new Date(value);
    } else {
      result[key] = value;
    }
  }
  return result;
}
function transformScoreRow(row, options = {}) {
  return transformRow(row, TABLE_SCORERS, options);
}
function toUpperSnakeCase(str) {
  return str.replace(/([a-z])([A-Z])/g, "$1_$2").replace(/([A-Z])([A-Z][a-z])/g, "$1_$2").toUpperCase().replace(/[^A-Z0-9]+/g, "_").replace(/^_+|_+$/g, "");
}
function createStoreErrorId(type, store, operation, status) {
  const normalizedStore = toUpperSnakeCase(store);
  const normalizedOperation = toUpperSnakeCase(operation);
  const normalizedStatus = toUpperSnakeCase(status);
  const typePrefix = type === "storage" ? "STORAGE" : "VECTOR";
  return `MASTRA_${typePrefix}_${normalizedStore}_${normalizedOperation}_${normalizedStatus}`;
}
function createStorageErrorId(store, operation, status) {
  return createStoreErrorId("storage", store, operation, status);
}
function createVectorErrorId(store, operation, status) {
  return createStoreErrorId("vector", store, operation, status);
}
function getSqlType(type) {
  switch (type) {
    case "text":
      return "TEXT";
    case "timestamp":
      return "TIMESTAMP";
    case "float":
      return "FLOAT";
    case "integer":
      return "INTEGER";
    case "bigint":
      return "BIGINT";
    case "jsonb":
      return "JSONB";
    case "boolean":
      return "BOOLEAN";
    default:
      return "TEXT";
  }
}
function getDefaultValue(type) {
  switch (type) {
    case "text":
    case "uuid":
      return "DEFAULT ''";
    case "timestamp":
      return "DEFAULT '1970-01-01 00:00:00'";
    case "integer":
    case "bigint":
    case "float":
      return "DEFAULT 0";
    case "jsonb":
      return "DEFAULT '{}'";
    case "boolean":
      return "DEFAULT FALSE";
    default:
      return "DEFAULT ''";
  }
}
function ensureDate(date) {
  if (!date) return void 0;
  return date instanceof Date ? date : new Date(date);
}
function serializeDate(date) {
  if (!date) return void 0;
  const dateObj = ensureDate(date);
  return dateObj?.toISOString();
}
function filterByDateRange(items, getCreatedAt, dateRange) {
  if (!dateRange) return items;
  let result = items;
  if (dateRange.start) {
    const startTime = ensureDate(dateRange.start).getTime();
    result = result.filter((item) => {
      const itemTime = getCreatedAt(item).getTime();
      return dateRange.startExclusive ? itemTime > startTime : itemTime >= startTime;
    });
  }
  if (dateRange.end) {
    const endTime = ensureDate(dateRange.end).getTime();
    result = result.filter((item) => {
      const itemTime = getCreatedAt(item).getTime();
      return dateRange.endExclusive ? itemTime < endTime : itemTime <= endTime;
    });
  }
  return result;
}
function jsonValueEquals(a, b) {
  if (a === void 0 || b === void 0) {
    return a === b;
  }
  if (a === null || b === null) {
    return a === b;
  }
  if (typeof a !== typeof b) {
    return false;
  }
  if (a instanceof Date && b instanceof Date) {
    return a.getTime() === b.getTime();
  }
  if (a instanceof Date || b instanceof Date) {
    return false;
  }
  if (typeof a === "object") {
    if (Array.isArray(a) && Array.isArray(b)) {
      if (a.length !== b.length) return false;
      return a.every((val, i) => jsonValueEquals(val, b[i]));
    }
    if (Array.isArray(a) || Array.isArray(b)) {
      return false;
    }
    const aKeys = Object.keys(a);
    const bKeys = Object.keys(b);
    if (aKeys.length !== bKeys.length) return false;
    return aKeys.every(
      (key) => jsonValueEquals(a[key], b[key])
    );
  }
  return a === b;
}

// src/storage/domains/memory/base.ts
var SAFE_METADATA_KEY_PATTERN = /^[a-zA-Z_][a-zA-Z0-9_]*$/;
var MAX_METADATA_KEY_LENGTH = 128;
var DISALLOWED_METADATA_KEYS = /* @__PURE__ */ new Set(["__proto__", "prototype", "constructor"]);
var MemoryStorage = class extends StorageDomain {
  /**
   * Whether this storage adapter supports Observational Memory.
   * Adapters that implement OM methods should set this to true.
   * Defaults to false for backwards compatibility with custom adapters.
   */
  supportsObservationalMemory = false;
  constructor() {
    super({
      component: "STORAGE",
      name: "MEMORY"
    });
  }
  /**
   * List messages by resource ID only (across all threads).
   * Used by Observational Memory and LongMemEval for resource-scoped queries.
   *
   * @param args - Resource ID and pagination/filtering options
   * @returns Paginated list of messages for the resource
   */
  async listMessagesByResourceId(_args) {
    throw new Error(
      `Resource-scoped message listing is not implemented by this storage adapter (${this.constructor.name}). Use an adapter that supports Observational Memory (pg, libsql, mongodb) or disable observational memory.`
    );
  }
  async deleteMessages(_messageIds) {
    throw new Error(
      `Message deletion is not supported by this storage adapter (${this.constructor.name}). The deleteMessages method needs to be implemented in the storage adapter.`
    );
  }
  /**
   * Clone a thread and its messages to create a new independent thread.
   * The cloned thread will have clone metadata stored in its metadata field.
   *
   * @param args - Clone configuration options
   * @returns The newly created thread and the cloned messages
   */
  async cloneThread(_args) {
    throw new Error(
      `Thread cloning is not implemented by this storage adapter (${this.constructor.name}). The cloneThread method needs to be implemented in the storage adapter.`
    );
  }
  async getResourceById(_) {
    throw new Error(
      `Resource working memory is not implemented by this storage adapter (${this.constructor.name}). This is likely a bug - all Mastra storage adapters should implement resource support. Please report this issue at https://github.com/mastra-ai/mastra/issues`
    );
  }
  async saveResource(_) {
    throw new Error(
      `Resource working memory is not implemented by this storage adapter (${this.constructor.name}). This is likely a bug - all Mastra storage adapters should implement resource support. Please report this issue at https://github.com/mastra-ai/mastra/issues`
    );
  }
  async updateResource(_) {
    throw new Error(
      `Resource working memory is not implemented by this storage adapter (${this.constructor.name}). This is likely a bug - all Mastra storage adapters should implement resource support. Please report this issue at https://github.com/mastra-ai/mastra/issues`
    );
  }
  parseOrderBy(orderBy, defaultDirection = "DESC") {
    return {
      field: orderBy?.field && orderBy.field in THREAD_ORDER_BY_SET ? orderBy.field : "createdAt",
      direction: orderBy?.direction && orderBy.direction in THREAD_THREAD_SORT_DIRECTION_SET ? orderBy.direction : defaultDirection
    };
  }
  // ============================================
  // Observational Memory Methods
  // ============================================
  /**
   * Get the current observational memory record for a thread/resource.
   * Returns the most recent active record.
   */
  async getObservationalMemory(_threadId, _resourceId) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Get observational memory history (previous generations).
   * Returns records in reverse chronological order (newest first).
   */
  async getObservationalMemoryHistory(_threadId, _resourceId, _limit) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Create a new observational memory record.
   * Called when starting observations for a new thread/resource.
   */
  async initializeObservationalMemory(_input) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Update active observations.
   * Called when observations are created and immediately activated (no buffering).
   */
  async updateActiveObservations(_input) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  // ============================================
  // Buffering Methods (for async observation/reflection)
  // These methods support async buffering when `bufferTokens` is configured.
  // ============================================
  /**
   * Update buffered observations.
   * Called when observations are created asynchronously via `bufferTokens`.
   */
  async updateBufferedObservations(_input) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Swap buffered observations to active.
   * Atomic operation that:
   * 1. Appends bufferedObservations → activeObservations (based on activationRatio)
   * 2. Moves activated bufferedMessageIds → observedMessageIds
   * 3. Keeps remaining buffered content if activationRatio < 100
   * 4. Updates lastObservedAt
   *
   * Returns info about what was activated for UI feedback.
   */
  async swapBufferedToActive(_input) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Create a new generation from a reflection.
   * Creates a new record with:
   * - originType: 'reflection'
   * - activeObservations containing the reflection
   * - generationCount incremented from the current record
   */
  async createReflectionGeneration(_input) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Update buffered reflection (async reflection in progress).
   * Called when reflection runs asynchronously via `bufferTokens`.
   */
  async updateBufferedReflection(_input) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Swap buffered reflection to active observations.
   * Creates a new generation where activeObservations = bufferedReflection + unreflected observations.
   * The `tokenCount` in input is the processor-computed token count for the combined content.
   */
  async swapBufferedReflectionToActive(_input) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Set the isReflecting flag.
   */
  async setReflectingFlag(_id, _isReflecting) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Set the isObserving flag.
   */
  async setObservingFlag(_id, _isObserving) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Set the isBufferingObservation flag and update lastBufferedAtTokens.
   * Called when async observation buffering starts (true) or ends/fails (false).
   * @param id - Record ID
   * @param isBuffering - Whether buffering is in progress
   * @param lastBufferedAtTokens - The pending token count at which this buffer was triggered (only set when isBuffering=true)
   */
  async setBufferingObservationFlag(_id, _isBuffering, _lastBufferedAtTokens) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Set the isBufferingReflection flag.
   * Called when async reflection buffering starts (true) or ends/fails (false).
   */
  async setBufferingReflectionFlag(_id, _isBuffering) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Clear all observational memory for a thread/resource.
   * Removes all records and history.
   */
  async clearObservationalMemory(_threadId, _resourceId) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Set the pending message token count.
   * Called at the end of each OM processing step to persist the current
   * context window token count so the UI can display it on page load.
   */
  async setPendingMessageTokens(_id, _tokenCount) {
    throw new Error(`Observational memory is not implemented by this storage adapter (${this.constructor.name}).`);
  }
  /**
   * Validates metadata keys to prevent SQL injection attacks and prototype pollution.
   * Keys must start with a letter or underscore, followed by alphanumeric characters or underscores.
   * @param metadata - The metadata object to validate
   * @throws Error if any key contains invalid characters or is a disallowed key
   */
  validateMetadataKeys(metadata) {
    if (!metadata) return;
    for (const key of Object.keys(metadata)) {
      if (DISALLOWED_METADATA_KEYS.has(key)) {
        throw new Error(`Invalid metadata key: "${key}".`);
      }
      if (!SAFE_METADATA_KEY_PATTERN.test(key)) {
        throw new Error(
          `Invalid metadata key: "${key}". Keys must start with a letter or underscore and contain only alphanumeric characters and underscores.`
        );
      }
      if (key.length > MAX_METADATA_KEY_LENGTH) {
        throw new Error(`Metadata key "${key}" exceeds maximum length of ${MAX_METADATA_KEY_LENGTH} characters.`);
      }
    }
  }
  /**
   * Validates pagination parameters and returns safe offset.
   * @param page - Page number (0-indexed)
   * @param perPage - Items per page (0 is allowed and returns empty results)
   * @throws Error if page is negative, perPage is negative/invalid, or offset would overflow
   */
  validatePagination(page, perPage) {
    if (!Number.isFinite(page) || !Number.isSafeInteger(page) || page < 0) {
      throw new Error("page must be >= 0");
    }
    if (!Number.isFinite(perPage) || !Number.isSafeInteger(perPage) || perPage < 0) {
      throw new Error("perPage must be >= 0");
    }
    if (perPage === 0) {
      return;
    }
    const offset = page * perPage;
    if (!Number.isSafeInteger(offset) || offset > Number.MAX_SAFE_INTEGER) {
      throw new Error("page value too large");
    }
  }
  /**
   * Validates pagination input before normalization.
   * Use this when accepting raw perPageInput (number | false) from callers.
   *
   * When perPage is false (fetch all), page must be 0 since pagination is disabled.
   * When perPage is a number, delegates to validatePagination for full validation.
   *
   * @param page - Page number (0-indexed)
   * @param perPageInput - Items per page as number, or false to fetch all results
   * @throws Error if perPageInput is false and page !== 0
   * @throws Error if perPageInput is invalid (not false or a non-negative safe integer)
   * @throws Error if page is invalid or offset would overflow
   */
  validatePaginationInput(page, perPageInput) {
    if (perPageInput !== false) {
      if (typeof perPageInput !== "number" || !Number.isFinite(perPageInput) || !Number.isSafeInteger(perPageInput)) {
        throw new Error("perPage must be false or a safe integer");
      }
      if (perPageInput < 0) {
        throw new Error("perPage must be >= 0");
      }
    }
    if (perPageInput === false) {
      if (page !== 0) {
        throw new Error("page must be 0 when perPage is false");
      }
      if (!Number.isFinite(page) || !Number.isSafeInteger(page)) {
        throw new Error("page must be >= 0");
      }
      return;
    }
    this.validatePagination(page, perPageInput);
  }
};
var THREAD_ORDER_BY_SET = {
  createdAt: true,
  updatedAt: true
};
var THREAD_THREAD_SORT_DIRECTION_SET = {
  ASC: true,
  DESC: true
};

// src/storage/domains/memory/inmemory.ts
var InMemoryMemory = class extends MemoryStorage {
  supportsObservationalMemory = true;
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.threads.clear();
    this.db.messages.clear();
    this.db.resources.clear();
    this.db.observationalMemory.clear();
  }
  async getThreadById({ threadId }) {
    this.logger.debug(`InMemoryMemory: getThreadById called for ${threadId}`);
    const thread = this.db.threads.get(threadId);
    return thread ? { ...thread, metadata: thread.metadata ? { ...thread.metadata } : thread.metadata } : null;
  }
  async saveThread({ thread }) {
    this.logger.debug(`InMemoryMemory: saveThread called for ${thread.id}`);
    const key = thread.id;
    this.db.threads.set(key, thread);
    return thread;
  }
  async updateThread({
    id,
    title,
    metadata
  }) {
    this.logger.debug(`InMemoryMemory: updateThread called for ${id}`);
    const thread = this.db.threads.get(id);
    if (!thread) {
      throw new Error(`Thread with id ${id} not found`);
    }
    if (thread) {
      thread.title = title;
      thread.metadata = { ...thread.metadata, ...metadata };
      thread.updatedAt = /* @__PURE__ */ new Date();
    }
    return thread;
  }
  async deleteThread({ threadId }) {
    this.logger.debug(`InMemoryMemory: deleteThread called for ${threadId}`);
    this.db.threads.delete(threadId);
    this.db.messages.forEach((msg, key) => {
      if (msg.thread_id === threadId) {
        this.db.messages.delete(key);
      }
    });
  }
  async listMessages({
    threadId,
    resourceId: optionalResourceId,
    include,
    filter,
    perPage: perPageInput,
    page = 0,
    orderBy
  }) {
    const threadIds = Array.isArray(threadId) ? threadId : [threadId];
    this.logger.debug(`InMemoryMemory: listMessages called for threads ${threadIds.join(", ")}`);
    if (threadIds.length === 0 || threadIds.some((id) => !id.trim())) {
      throw new Error("threadId must be a non-empty string or array of non-empty strings");
    }
    const threadIdSet = new Set(threadIds);
    const { field, direction } = this.parseOrderBy(orderBy, "ASC");
    const perPage = normalizePerPage(perPageInput, 40);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    let threadMessages = Array.from(this.db.messages.values()).filter((msg) => {
      if (threadIdSet && !threadIdSet.has(msg.thread_id)) return false;
      if (optionalResourceId && msg.resourceId !== optionalResourceId) return false;
      return true;
    });
    threadMessages = filterByDateRange(threadMessages, (msg) => new Date(msg.createdAt), filter?.dateRange);
    threadMessages.sort((a, b) => {
      const isDateField = field === "createdAt" || field === "updatedAt";
      const aValue = isDateField ? new Date(a[field]).getTime() : a[field];
      const bValue = isDateField ? new Date(b[field]).getTime() : b[field];
      if (typeof aValue === "number" && typeof bValue === "number") {
        return direction === "ASC" ? aValue - bValue : bValue - aValue;
      }
      return direction === "ASC" ? String(aValue).localeCompare(String(bValue)) : String(bValue).localeCompare(String(aValue));
    });
    const totalThreadMessages = threadMessages.length;
    const start = offset;
    const end = start + perPage;
    const paginatedThreadMessages = threadMessages.slice(start, end);
    const messages = [];
    const messageIds = /* @__PURE__ */ new Set();
    for (const msg of paginatedThreadMessages) {
      const convertedMessage = this.parseStoredMessage(msg);
      messages.push(convertedMessage);
      messageIds.add(msg.id);
    }
    if (include && include.length > 0) {
      for (const includeItem of include) {
        const targetMessage = this.db.messages.get(includeItem.id);
        if (targetMessage) {
          const convertedMessage = {
            id: targetMessage.id,
            threadId: targetMessage.thread_id,
            content: safelyParseJSON(targetMessage.content),
            role: targetMessage.role,
            type: targetMessage.type,
            createdAt: targetMessage.createdAt,
            resourceId: targetMessage.resourceId
          };
          if (!messageIds.has(convertedMessage.id)) {
            messages.push(convertedMessage);
            messageIds.add(convertedMessage.id);
          }
          if (includeItem.withPreviousMessages) {
            const allThreadMessages = Array.from(this.db.messages.values()).filter((msg) => msg.thread_id === (includeItem.threadId || threadId)).sort((a, b) => new Date(a.createdAt).getTime() - new Date(b.createdAt).getTime());
            const targetIndex = allThreadMessages.findIndex((msg) => msg.id === includeItem.id);
            if (targetIndex !== -1) {
              const startIndex = Math.max(0, targetIndex - (includeItem.withPreviousMessages || 0));
              for (let i = startIndex; i < targetIndex; i++) {
                const message = allThreadMessages[i];
                if (message && !messageIds.has(message.id)) {
                  const convertedPrevMessage = {
                    id: message.id,
                    threadId: message.thread_id,
                    content: safelyParseJSON(message.content),
                    role: message.role,
                    type: message.type,
                    createdAt: message.createdAt,
                    resourceId: message.resourceId
                  };
                  messages.push(convertedPrevMessage);
                  messageIds.add(message.id);
                }
              }
            }
          }
          if (includeItem.withNextMessages) {
            const allThreadMessages = Array.from(this.db.messages.values()).filter((msg) => msg.thread_id === (includeItem.threadId || threadId)).sort((a, b) => new Date(a.createdAt).getTime() - new Date(b.createdAt).getTime());
            const targetIndex = allThreadMessages.findIndex((msg) => msg.id === includeItem.id);
            if (targetIndex !== -1) {
              const endIndex = Math.min(
                allThreadMessages.length,
                targetIndex + (includeItem.withNextMessages || 0) + 1
              );
              for (let i = targetIndex + 1; i < endIndex; i++) {
                const message = allThreadMessages[i];
                if (message && !messageIds.has(message.id)) {
                  const convertedNextMessage = {
                    id: message.id,
                    threadId: message.thread_id,
                    content: safelyParseJSON(message.content),
                    role: message.role,
                    type: message.type,
                    createdAt: message.createdAt,
                    resourceId: message.resourceId
                  };
                  messages.push(convertedNextMessage);
                  messageIds.add(message.id);
                }
              }
            }
          }
        }
      }
    }
    messages.sort((a, b) => {
      const isDateField = field === "createdAt" || field === "updatedAt";
      const aValue = isDateField ? new Date(a[field]).getTime() : a[field];
      const bValue = isDateField ? new Date(b[field]).getTime() : b[field];
      if (typeof aValue === "number" && typeof bValue === "number") {
        return direction === "ASC" ? aValue - bValue : bValue - aValue;
      }
      return direction === "ASC" ? String(aValue).localeCompare(String(bValue)) : String(bValue).localeCompare(String(aValue));
    });
    let hasMore;
    if (include && include.length > 0) {
      const returnedThreadMessageIds = new Set(messages.filter((m) => m.threadId === threadId).map((m) => m.id));
      hasMore = returnedThreadMessageIds.size < totalThreadMessages;
    } else {
      hasMore = end < totalThreadMessages;
    }
    return {
      messages,
      total: totalThreadMessages,
      page,
      perPage: perPageForResponse,
      hasMore
    };
  }
  async listMessagesByResourceId({
    resourceId,
    filter,
    perPage: perPageInput,
    page = 0,
    orderBy
  }) {
    this.logger.debug(`InMemoryMemory: listMessagesByResourceId called for resource ${resourceId}`);
    const { field, direction } = this.parseOrderBy(orderBy, "ASC");
    const perPage = normalizePerPage(perPageInput, 40);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    let messages = Array.from(this.db.messages.values()).filter((msg) => msg.resourceId === resourceId);
    messages = filterByDateRange(messages, (msg) => new Date(msg.createdAt), filter?.dateRange);
    messages.sort((a, b) => {
      const isDateField = field === "createdAt" || field === "updatedAt";
      const aValue = isDateField ? new Date(a[field]).getTime() : a[field];
      const bValue = isDateField ? new Date(b[field]).getTime() : b[field];
      if (typeof aValue === "number" && typeof bValue === "number") {
        return direction === "ASC" ? aValue - bValue : bValue - aValue;
      }
      return direction === "ASC" ? String(aValue).localeCompare(String(bValue)) : String(bValue).localeCompare(String(aValue));
    });
    const total = messages.length;
    const paginatedMessages = messages.slice(offset, offset + perPage);
    const list = new MessageList().add(
      paginatedMessages.map((m) => this.parseStoredMessage(m)),
      "memory"
    );
    const hasMore = offset + paginatedMessages.length < total;
    return {
      messages: list.get.all.db(),
      total,
      page,
      perPage: perPageForResponse,
      hasMore
    };
  }
  parseStoredMessage(message) {
    const { resourceId, content, role, thread_id, ...rest } = message;
    let parsedContent = safelyParseJSON(content);
    if (typeof parsedContent === "string") {
      parsedContent = {
        format: 2,
        content: parsedContent,
        parts: [{ type: "text", text: parsedContent }]
      };
    }
    return {
      ...rest,
      threadId: thread_id,
      ...message.resourceId && { resourceId: message.resourceId },
      content: parsedContent,
      role
    };
  }
  async listMessagesById({ messageIds }) {
    this.logger.debug(`InMemoryMemory: listMessagesById called`);
    const rawMessages = messageIds.map((id) => this.db.messages.get(id)).filter((message) => !!message);
    const list = new MessageList().add(
      rawMessages.map((m) => this.parseStoredMessage(m)),
      "memory"
    );
    return { messages: list.get.all.db() };
  }
  async saveMessages(args) {
    const { messages } = args;
    this.logger.debug(`InMemoryMemory: saveMessages called with ${messages.length} messages`);
    if (messages.some((msg) => msg.id === "error-message" || msg.resourceId === null)) {
      throw new Error("Simulated error for testing");
    }
    const threadIds = new Set(messages.map((msg) => msg.threadId).filter((id) => Boolean(id)));
    for (const threadId of threadIds) {
      const thread = this.db.threads.get(threadId);
      if (thread) {
        thread.updatedAt = /* @__PURE__ */ new Date();
      }
    }
    for (const message of messages) {
      const key = message.id;
      const storageMessage = {
        id: message.id,
        thread_id: message.threadId || "",
        content: JSON.stringify(message.content),
        role: message.role || "user",
        type: message.type || "text",
        createdAt: message.createdAt,
        resourceId: message.resourceId || null
      };
      this.db.messages.set(key, storageMessage);
    }
    const list = new MessageList().add(messages, "memory");
    return { messages: list.get.all.db() };
  }
  async updateMessages(args) {
    const updatedMessages = [];
    for (const update of args.messages) {
      const storageMsg = this.db.messages.get(update.id);
      if (!storageMsg) continue;
      const oldThreadId = storageMsg.thread_id;
      const newThreadId = update.threadId || oldThreadId;
      let threadIdChanged = false;
      if (update.threadId && update.threadId !== oldThreadId) {
        threadIdChanged = true;
      }
      if (update.role !== void 0) storageMsg.role = update.role;
      if (update.type !== void 0) storageMsg.type = update.type;
      if (update.createdAt !== void 0) storageMsg.createdAt = update.createdAt;
      if (update.resourceId !== void 0) storageMsg.resourceId = update.resourceId;
      if (update.content !== void 0) {
        let oldContent = safelyParseJSON(storageMsg.content);
        let newContent = update.content;
        if (typeof newContent === "object" && typeof oldContent === "object") {
          newContent = { ...oldContent, ...newContent };
          if (oldContent.metadata && newContent.metadata) {
            newContent.metadata = { ...oldContent.metadata, ...newContent.metadata };
          }
        }
        storageMsg.content = JSON.stringify(newContent);
      }
      if (threadIdChanged) {
        storageMsg.thread_id = newThreadId;
        const base = Date.now();
        let oldThreadNewTime;
        const oldThread = this.db.threads.get(oldThreadId);
        if (oldThread) {
          const prev = new Date(oldThread.updatedAt).getTime();
          oldThreadNewTime = Math.max(base, prev + 1);
          oldThread.updatedAt = new Date(oldThreadNewTime);
        }
        const newThread = this.db.threads.get(newThreadId);
        if (newThread) {
          const prev = new Date(newThread.updatedAt).getTime();
          let newThreadNewTime = Math.max(base + 1, prev + 1);
          if (oldThreadNewTime !== void 0 && newThreadNewTime <= oldThreadNewTime) {
            newThreadNewTime = oldThreadNewTime + 1;
          }
          newThread.updatedAt = new Date(newThreadNewTime);
        }
      } else {
        const thread = this.db.threads.get(oldThreadId);
        if (thread) {
          const prev = new Date(thread.updatedAt).getTime();
          let newTime = Date.now();
          if (newTime <= prev) newTime = prev + 1;
          thread.updatedAt = new Date(newTime);
        }
      }
      this.db.messages.set(update.id, storageMsg);
      updatedMessages.push({
        id: storageMsg.id,
        threadId: storageMsg.thread_id,
        content: safelyParseJSON(storageMsg.content),
        role: storageMsg.role === "user" || storageMsg.role === "assistant" ? storageMsg.role : "user",
        type: storageMsg.type,
        createdAt: storageMsg.createdAt,
        resourceId: storageMsg.resourceId === null ? void 0 : storageMsg.resourceId
      });
    }
    return updatedMessages;
  }
  async deleteMessages(messageIds) {
    if (!messageIds || messageIds.length === 0) {
      return;
    }
    this.logger.debug(`InMemoryMemory: deleteMessages called for ${messageIds.length} messages`);
    const threadIds = /* @__PURE__ */ new Set();
    for (const messageId of messageIds) {
      const message = this.db.messages.get(messageId);
      if (message && message.thread_id) {
        threadIds.add(message.thread_id);
      }
      this.db.messages.delete(messageId);
    }
    const now = /* @__PURE__ */ new Date();
    for (const threadId of threadIds) {
      const thread = this.db.threads.get(threadId);
      if (thread) {
        thread.updatedAt = now;
      }
    }
  }
  async listThreads(args) {
    const { page = 0, perPage: perPageInput, orderBy, filter } = args;
    const { field, direction } = this.parseOrderBy(orderBy);
    this.validatePaginationInput(page, perPageInput ?? 100);
    const perPage = normalizePerPage(perPageInput, 100);
    this.logger.debug(`InMemoryMemory: listThreads called with filter: ${JSON.stringify(filter)}`);
    let threads = Array.from(this.db.threads.values());
    if (filter?.resourceId) {
      threads = threads.filter((t) => t.resourceId === filter.resourceId);
    }
    this.validateMetadataKeys(filter?.metadata);
    if (filter?.metadata && Object.keys(filter.metadata).length > 0) {
      threads = threads.filter((thread) => {
        if (!thread.metadata) return false;
        return Object.entries(filter.metadata).every(([key, value]) => jsonValueEquals(thread.metadata[key], value));
      });
    }
    const sortedThreads = this.sortThreads(threads, field, direction);
    const clonedThreads = sortedThreads.map((thread) => ({
      ...thread,
      metadata: thread.metadata ? { ...thread.metadata } : thread.metadata
    }));
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    return {
      threads: clonedThreads.slice(offset, offset + perPage),
      total: clonedThreads.length,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < clonedThreads.length
    };
  }
  async getResourceById({ resourceId }) {
    this.logger.debug(`InMemoryMemory: getResourceById called for ${resourceId}`);
    const resource = this.db.resources.get(resourceId);
    return resource ? { ...resource, metadata: resource.metadata ? { ...resource.metadata } : resource.metadata } : null;
  }
  async saveResource({ resource }) {
    this.logger.debug(`InMemoryMemory: saveResource called for ${resource.id}`);
    this.db.resources.set(resource.id, resource);
    return resource;
  }
  async updateResource({
    resourceId,
    workingMemory,
    metadata
  }) {
    this.logger.debug(`InMemoryMemory: updateResource called for ${resourceId}`);
    let resource = this.db.resources.get(resourceId);
    if (!resource) {
      resource = {
        id: resourceId,
        workingMemory,
        metadata: metadata || {},
        createdAt: /* @__PURE__ */ new Date(),
        updatedAt: /* @__PURE__ */ new Date()
      };
    } else {
      resource = {
        ...resource,
        workingMemory: workingMemory !== void 0 ? workingMemory : resource.workingMemory,
        metadata: {
          ...resource.metadata,
          ...metadata
        },
        updatedAt: /* @__PURE__ */ new Date()
      };
    }
    this.db.resources.set(resourceId, resource);
    return resource;
  }
  async cloneThread(args) {
    const { sourceThreadId, newThreadId: providedThreadId, resourceId, title, metadata, options } = args;
    this.logger.debug(`InMemoryMemory: cloneThread called for source thread ${sourceThreadId}`);
    const sourceThread = this.db.threads.get(sourceThreadId);
    if (!sourceThread) {
      throw new Error(`Source thread with id ${sourceThreadId} not found`);
    }
    const newThreadId = providedThreadId || crypto.randomUUID();
    if (this.db.threads.has(newThreadId)) {
      throw new Error(`Thread with id ${newThreadId} already exists`);
    }
    let sourceMessages = Array.from(this.db.messages.values()).filter((msg) => msg.thread_id === sourceThreadId).sort((a, b) => new Date(a.createdAt).getTime() - new Date(b.createdAt).getTime());
    if (options?.messageFilter) {
      const { startDate, endDate, messageIds } = options.messageFilter;
      if (messageIds && messageIds.length > 0) {
        const messageIdSet = new Set(messageIds);
        sourceMessages = sourceMessages.filter((msg) => messageIdSet.has(msg.id));
      }
      if (startDate) {
        sourceMessages = sourceMessages.filter((msg) => new Date(msg.createdAt) >= startDate);
      }
      if (endDate) {
        sourceMessages = sourceMessages.filter((msg) => new Date(msg.createdAt) <= endDate);
      }
    }
    if (options?.messageLimit && options.messageLimit > 0 && sourceMessages.length > options.messageLimit) {
      sourceMessages = sourceMessages.slice(-options.messageLimit);
    }
    const now = /* @__PURE__ */ new Date();
    const lastMessageId = sourceMessages.length > 0 ? sourceMessages[sourceMessages.length - 1].id : void 0;
    const cloneMetadata = {
      sourceThreadId,
      clonedAt: now,
      ...lastMessageId && { lastMessageId }
    };
    const newThread = {
      id: newThreadId,
      resourceId: resourceId || sourceThread.resourceId,
      title: title || (sourceThread.title ? `Clone of ${sourceThread.title}` : void 0),
      metadata: {
        ...metadata,
        clone: cloneMetadata
      },
      createdAt: now,
      updatedAt: now
    };
    this.db.threads.set(newThreadId, newThread);
    const clonedMessages = [];
    for (const sourceMsg of sourceMessages) {
      const newMessageId = crypto.randomUUID();
      const parsedContent = safelyParseJSON(sourceMsg.content);
      const newStorageMessage = {
        id: newMessageId,
        thread_id: newThreadId,
        content: sourceMsg.content,
        role: sourceMsg.role,
        type: sourceMsg.type,
        createdAt: sourceMsg.createdAt,
        resourceId: resourceId || sourceMsg.resourceId
      };
      this.db.messages.set(newMessageId, newStorageMessage);
      clonedMessages.push({
        id: newMessageId,
        threadId: newThreadId,
        content: parsedContent,
        role: sourceMsg.role,
        type: sourceMsg.type,
        createdAt: sourceMsg.createdAt,
        resourceId: resourceId || sourceMsg.resourceId || void 0
      });
    }
    this.logger.debug(
      `InMemoryMemory: cloned thread ${sourceThreadId} to ${newThreadId} with ${clonedMessages.length} messages`
    );
    return {
      thread: newThread,
      clonedMessages
    };
  }
  sortThreads(threads, field, direction) {
    return threads.sort((a, b) => {
      const isDateField = field === "createdAt" || field === "updatedAt";
      const aValue = isDateField ? new Date(a[field]).getTime() : a[field];
      const bValue = isDateField ? new Date(b[field]).getTime() : b[field];
      if (typeof aValue === "number" && typeof bValue === "number") {
        if (direction === "ASC") {
          return aValue - bValue;
        } else {
          return bValue - aValue;
        }
      }
      return direction === "ASC" ? String(aValue).localeCompare(String(bValue)) : String(bValue).localeCompare(String(aValue));
    });
  }
  // ============================================
  // Observational Memory Implementation
  // ============================================
  getObservationalMemoryKey(threadId, resourceId) {
    if (threadId) {
      return `thread:${threadId}`;
    }
    return `resource:${resourceId}`;
  }
  async getObservationalMemory(threadId, resourceId) {
    const key = this.getObservationalMemoryKey(threadId, resourceId);
    const records = this.db.observationalMemory.get(key);
    return records?.[0] ?? null;
  }
  async getObservationalMemoryHistory(threadId, resourceId, limit) {
    const key = this.getObservationalMemoryKey(threadId, resourceId);
    const records = this.db.observationalMemory.get(key) ?? [];
    return limit != null ? records.slice(0, limit) : records;
  }
  async initializeObservationalMemory(input) {
    const { threadId, resourceId, scope, config, observedTimezone } = input;
    const key = this.getObservationalMemoryKey(threadId, resourceId);
    const now = /* @__PURE__ */ new Date();
    const record = {
      id: crypto.randomUUID(),
      scope,
      threadId,
      resourceId,
      // Timestamps at top level
      createdAt: now,
      updatedAt: now,
      // lastObservedAt starts undefined - all messages are "unobserved" initially
      // This ensures historical data (like LongMemEval fixtures) works correctly
      lastObservedAt: void 0,
      originType: "initial",
      generationCount: 0,
      activeObservations: "",
      // Buffering (for async observation/reflection)
      bufferedObservations: void 0,
      bufferedReflection: void 0,
      // Message tracking
      // Note: Message ID tracking removed in favor of cursor-based lastObservedAt
      // Token tracking
      totalTokensObserved: 0,
      observationTokenCount: 0,
      pendingMessageTokens: 0,
      // State flags
      isReflecting: false,
      isObserving: false,
      isBufferingObservation: false,
      isBufferingReflection: false,
      lastBufferedAtTokens: 0,
      lastBufferedAtTime: null,
      // Configuration
      config,
      // Timezone used for observation date formatting
      observedTimezone,
      // Extensible metadata (optional)
      metadata: {}
    };
    const existing = this.db.observationalMemory.get(key) ?? [];
    this.db.observationalMemory.set(key, [record, ...existing]);
    return record;
  }
  async updateActiveObservations(input) {
    const { id, observations, tokenCount, lastObservedAt, observedMessageIds } = input;
    const record = this.findObservationalMemoryRecordById(id);
    if (!record) {
      throw new Error(`Observational memory record not found: ${id}`);
    }
    record.activeObservations = observations;
    record.observationTokenCount = tokenCount;
    record.totalTokensObserved += tokenCount;
    record.pendingMessageTokens = 0;
    record.lastObservedAt = lastObservedAt;
    record.updatedAt = /* @__PURE__ */ new Date();
    if (observedMessageIds) {
      record.observedMessageIds = observedMessageIds;
    }
  }
  async updateBufferedObservations(input) {
    const { id, chunk } = input;
    const record = this.findObservationalMemoryRecordById(id);
    if (!record) {
      throw new Error(`Observational memory record not found: ${id}`);
    }
    const newChunk = {
      id: `ombuf-${crypto.randomUUID()}`,
      cycleId: chunk.cycleId,
      observations: chunk.observations,
      tokenCount: chunk.tokenCount,
      messageIds: chunk.messageIds,
      messageTokens: chunk.messageTokens,
      lastObservedAt: chunk.lastObservedAt,
      createdAt: /* @__PURE__ */ new Date(),
      suggestedContinuation: chunk.suggestedContinuation,
      currentTask: chunk.currentTask
    };
    const existingChunks = Array.isArray(record.bufferedObservationChunks) ? record.bufferedObservationChunks : [];
    record.bufferedObservationChunks = [...existingChunks, newChunk];
    if (input.lastBufferedAtTime) {
      record.lastBufferedAtTime = input.lastBufferedAtTime;
    }
    record.updatedAt = /* @__PURE__ */ new Date();
  }
  async swapBufferedToActive(input) {
    const { id, activationRatio, lastObservedAt } = input;
    const record = this.findObservationalMemoryRecordById(id);
    if (!record) {
      throw new Error(`Observational memory record not found: ${id}`);
    }
    const chunks = Array.isArray(record.bufferedObservationChunks) ? record.bufferedObservationChunks : [];
    if (chunks.length === 0) {
      return {
        chunksActivated: 0,
        messageTokensActivated: 0,
        observationTokensActivated: 0,
        messagesActivated: 0,
        activatedCycleIds: [],
        activatedMessageIds: []
      };
    }
    const retentionFloor = input.messageTokensThreshold * (1 - activationRatio);
    const targetMessageTokens = Math.max(0, input.currentPendingTokens - retentionFloor);
    let cumulativeMessageTokens = 0;
    let bestBoundary = 0;
    let bestBoundaryMessageTokens = 0;
    for (let i = 0; i < chunks.length; i++) {
      cumulativeMessageTokens += chunks[i].messageTokens ?? 0;
      const boundary = i + 1;
      const isUnder = cumulativeMessageTokens <= targetMessageTokens;
      const bestIsUnder = bestBoundaryMessageTokens <= targetMessageTokens;
      if (bestBoundary === 0) {
        bestBoundary = boundary;
        bestBoundaryMessageTokens = cumulativeMessageTokens;
      } else if (isUnder && !bestIsUnder) {
        bestBoundary = boundary;
        bestBoundaryMessageTokens = cumulativeMessageTokens;
      } else if (isUnder && bestIsUnder) {
        if (cumulativeMessageTokens > bestBoundaryMessageTokens) {
          bestBoundary = boundary;
          bestBoundaryMessageTokens = cumulativeMessageTokens;
        }
      } else if (!isUnder && !bestIsUnder) {
        if (cumulativeMessageTokens < bestBoundaryMessageTokens) {
          bestBoundary = boundary;
          bestBoundaryMessageTokens = cumulativeMessageTokens;
        }
      }
    }
    const chunksToActivate = bestBoundary === 0 ? 1 : bestBoundary;
    const activatedChunks = chunks.slice(0, chunksToActivate);
    const remainingChunks = chunks.slice(chunksToActivate);
    const activatedContent = activatedChunks.map((c) => c.observations).join("\n\n");
    const activatedTokens = activatedChunks.reduce((sum, c) => sum + c.tokenCount, 0);
    const activatedMessageTokens = activatedChunks.reduce((sum, c) => sum + (c.messageTokens ?? 0), 0);
    const activatedMessageCount = activatedChunks.reduce((sum, c) => sum + c.messageIds.length, 0);
    const activatedCycleIds = activatedChunks.map((c) => c.cycleId).filter((id2) => !!id2);
    const activatedMessageIds = activatedChunks.flatMap((c) => c.messageIds);
    const latestChunk = activatedChunks[activatedChunks.length - 1];
    const derivedLastObservedAt = lastObservedAt ?? (latestChunk?.lastObservedAt ? new Date(latestChunk.lastObservedAt) : /* @__PURE__ */ new Date());
    if (record.activeObservations) {
      record.activeObservations = `${record.activeObservations}

${activatedContent}`;
    } else {
      record.activeObservations = activatedContent;
    }
    record.observationTokenCount = (record.observationTokenCount ?? 0) + activatedTokens;
    record.pendingMessageTokens = Math.max(0, (record.pendingMessageTokens ?? 0) - activatedMessageTokens);
    record.bufferedObservationChunks = remainingChunks.length > 0 ? remainingChunks : void 0;
    record.lastObservedAt = derivedLastObservedAt;
    record.updatedAt = /* @__PURE__ */ new Date();
    return {
      chunksActivated: activatedChunks.length,
      messageTokensActivated: activatedMessageTokens,
      observationTokensActivated: activatedTokens,
      messagesActivated: activatedMessageCount,
      activatedCycleIds,
      activatedMessageIds,
      observations: activatedContent,
      perChunk: activatedChunks.map((c) => ({
        cycleId: c.cycleId ?? "",
        messageTokens: c.messageTokens ?? 0,
        observationTokens: c.tokenCount,
        messageCount: c.messageIds.length,
        observations: c.observations
      }))
    };
  }
  async createReflectionGeneration(input) {
    const { currentRecord, reflection, tokenCount } = input;
    const key = this.getObservationalMemoryKey(currentRecord.threadId, currentRecord.resourceId);
    const now = /* @__PURE__ */ new Date();
    const newRecord = {
      id: crypto.randomUUID(),
      scope: currentRecord.scope,
      threadId: currentRecord.threadId,
      resourceId: currentRecord.resourceId,
      // Timestamps at top level
      createdAt: now,
      updatedAt: now,
      lastObservedAt: currentRecord.lastObservedAt ?? now,
      // Carry over from observation (which always runs before reflection)
      originType: "reflection",
      generationCount: currentRecord.generationCount + 1,
      activeObservations: reflection,
      config: currentRecord.config,
      totalTokensObserved: currentRecord.totalTokensObserved,
      observationTokenCount: tokenCount,
      pendingMessageTokens: 0,
      isReflecting: false,
      isObserving: false,
      isBufferingObservation: false,
      isBufferingReflection: false,
      lastBufferedAtTokens: 0,
      lastBufferedAtTime: null,
      // Timezone used for observation date formatting
      observedTimezone: currentRecord.observedTimezone,
      // Extensible metadata (optional)
      metadata: {}
    };
    const existing = this.db.observationalMemory.get(key) ?? [];
    this.db.observationalMemory.set(key, [newRecord, ...existing]);
    return newRecord;
  }
  async updateBufferedReflection(input) {
    const { id, reflection, tokenCount, inputTokenCount, reflectedObservationLineCount } = input;
    const record = this.findObservationalMemoryRecordById(id);
    if (!record) {
      throw new Error(`Observational memory record not found: ${id}`);
    }
    const existing = record.bufferedReflection || "";
    record.bufferedReflection = existing ? `${existing}

${reflection}` : reflection;
    record.bufferedReflectionTokens = (record.bufferedReflectionTokens || 0) + tokenCount;
    record.bufferedReflectionInputTokens = (record.bufferedReflectionInputTokens || 0) + inputTokenCount;
    record.reflectedObservationLineCount = reflectedObservationLineCount;
    record.updatedAt = /* @__PURE__ */ new Date();
  }
  async swapBufferedReflectionToActive(input) {
    const { currentRecord } = input;
    const record = this.findObservationalMemoryRecordById(currentRecord.id);
    if (!record) {
      throw new Error(`Observational memory record not found: ${currentRecord.id}`);
    }
    if (!record.bufferedReflection) {
      throw new Error("No buffered reflection to swap");
    }
    const bufferedReflection = record.bufferedReflection;
    const reflectedLineCount = record.reflectedObservationLineCount ?? 0;
    const currentObservations = record.activeObservations ?? "";
    const allLines = currentObservations.split("\n");
    const unreflectedLines = allLines.slice(reflectedLineCount);
    const unreflectedContent = unreflectedLines.join("\n").trim();
    const newObservations = unreflectedContent ? `${bufferedReflection}

${unreflectedContent}` : bufferedReflection;
    const newRecord = await this.createReflectionGeneration({
      currentRecord: record,
      reflection: newObservations,
      tokenCount: input.tokenCount
    });
    record.bufferedReflection = void 0;
    record.bufferedReflectionTokens = void 0;
    record.bufferedReflectionInputTokens = void 0;
    record.reflectedObservationLineCount = void 0;
    return newRecord;
  }
  async setReflectingFlag(id, isReflecting) {
    const record = this.findObservationalMemoryRecordById(id);
    if (!record) {
      throw new Error(`Observational memory record not found: ${id}`);
    }
    record.isReflecting = isReflecting;
    record.updatedAt = /* @__PURE__ */ new Date();
  }
  async setObservingFlag(id, isObserving) {
    const record = this.findObservationalMemoryRecordById(id);
    if (!record) {
      throw new Error(`Observational memory record not found: ${id}`);
    }
    record.isObserving = isObserving;
    record.updatedAt = /* @__PURE__ */ new Date();
  }
  async setBufferingObservationFlag(id, isBuffering, lastBufferedAtTokens) {
    const record = this.findObservationalMemoryRecordById(id);
    if (!record) {
      throw new Error(`Observational memory record not found: ${id}`);
    }
    record.isBufferingObservation = isBuffering;
    if (lastBufferedAtTokens !== void 0) {
      record.lastBufferedAtTokens = lastBufferedAtTokens;
    }
    record.updatedAt = /* @__PURE__ */ new Date();
  }
  async setBufferingReflectionFlag(id, isBuffering) {
    const record = this.findObservationalMemoryRecordById(id);
    if (!record) {
      throw new Error(`Observational memory record not found: ${id}`);
    }
    record.isBufferingReflection = isBuffering;
    record.updatedAt = /* @__PURE__ */ new Date();
  }
  async clearObservationalMemory(threadId, resourceId) {
    const key = this.getObservationalMemoryKey(threadId, resourceId);
    this.db.observationalMemory.delete(key);
  }
  async setPendingMessageTokens(id, tokenCount) {
    const record = this.findObservationalMemoryRecordById(id);
    if (!record) {
      throw new Error(`Observational memory record not found: ${id}`);
    }
    record.pendingMessageTokens = tokenCount;
    record.updatedAt = /* @__PURE__ */ new Date();
  }
  /**
   * Helper to find an observational memory record by ID across all keys
   */
  findObservationalMemoryRecordById(id) {
    for (const records of this.db.observationalMemory.values()) {
      const record = records.find((r) => r.id === id);
      if (record) return record;
    }
    return null;
  }
};

// src/storage/domains/observability/base.ts
var ObservabilityStorage = class extends StorageDomain {
  constructor() {
    super({
      component: "STORAGE",
      name: "OBSERVABILITY"
    });
  }
  async dangerouslyClearAll() {
  }
  /**
   * Provides hints for tracing strategy selection by the DefaultExporter.
   * Storage adapters can override this to specify their preferred and supported strategies.
   */
  get tracingStrategy() {
    return {
      preferred: "batch-with-updates",
      // Default for most SQL stores
      supported: ["realtime", "batch-with-updates", "insert-only"]
    };
  }
  /**
   * Creates a single Span record in the storage provider.
   */
  async createSpan(_args) {
    throw new MastraError({
      id: "OBSERVABILITY_CREATE_SPAN_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support creating spans"
    });
  }
  /**
   * Updates a single Span with partial data. Primarily used for realtime trace creation.
   */
  async updateSpan(_args) {
    throw new MastraError({
      id: "OBSERVABILITY_STORAGE_UPDATE_SPAN_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support updating spans"
    });
  }
  /**
   * Retrieves a single span.
   */
  async getSpan(_args) {
    throw new MastraError({
      id: "OBSERVABILITY_STORAGE_GET_SPAN_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support getting spans"
    });
  }
  /**
   * Retrieves a single root span.
   */
  async getRootSpan(_args) {
    throw new MastraError({
      id: "OBSERVABILITY_STORAGE_GET_ROOT_SPAN_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support getting root spans"
    });
  }
  /**
   * Retrieves a single trace with all its associated spans.
   */
  async getTrace(_args) {
    throw new MastraError({
      id: "OBSERVABILITY_STORAGE_GET_TRACE_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support getting traces"
    });
  }
  /**
   * Retrieves a list of traces with optional filtering.
   */
  async listTraces(_args) {
    throw new MastraError({
      id: "OBSERVABILITY_STORAGE_LIST_TRACES_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support listing traces"
    });
  }
  /**
   * Creates multiple Spans in a single batch.
   */
  async batchCreateSpans(_args) {
    throw new MastraError({
      id: "OBSERVABILITY_STORAGE_BATCH_CREATE_SPAN_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support batch creating spans"
    });
  }
  /**
   * Updates multiple Spans in a single batch.
   */
  async batchUpdateSpans(_args) {
    throw new MastraError({
      id: "OBSERVABILITY_STORAGE_BATCH_UPDATE_SPANS_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support batch updating spans"
    });
  }
  /**
   * Deletes multiple traces and all their associated spans in a single batch operation.
   */
  async batchDeleteTraces(_args) {
    throw new MastraError({
      id: "OBSERVABILITY_STORAGE_BATCH_DELETE_TRACES_NOT_IMPLEMENTED",
      domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
      category: "SYSTEM" /* SYSTEM */,
      text: "This storage provider does not support batch deleting traces"
    });
  }
};

// src/storage/domains/observability/inmemory.ts
var ObservabilityInMemory = class extends ObservabilityStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.traces.clear();
  }
  get tracingStrategy() {
    return {
      preferred: "realtime",
      supported: ["realtime", "batch-with-updates", "insert-only"]
    };
  }
  async createSpan(args) {
    const { span } = args;
    this.validateCreateSpan(span);
    const now = /* @__PURE__ */ new Date();
    const record = {
      ...span,
      createdAt: now,
      updatedAt: now
    };
    this.upsertSpanToTrace(record);
  }
  async batchCreateSpans(args) {
    const now = /* @__PURE__ */ new Date();
    for (const span of args.records) {
      this.validateCreateSpan(span);
      const record = {
        ...span,
        createdAt: now,
        updatedAt: now
      };
      this.upsertSpanToTrace(record);
    }
  }
  validateCreateSpan(record) {
    if (!record.spanId) {
      throw new MastraError({
        id: "OBSERVABILITY_SPAN_ID_REQUIRED",
        domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
        category: "SYSTEM" /* SYSTEM */,
        text: "Span ID is required for creating a span"
      });
    }
    if (!record.traceId) {
      throw new MastraError({
        id: "OBSERVABILITY_TRACE_ID_REQUIRED",
        domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
        category: "SYSTEM" /* SYSTEM */,
        text: "Trace ID is required for creating a span"
      });
    }
  }
  /**
   * Inserts or updates a span in the trace and recomputes trace-level properties
   */
  upsertSpanToTrace(span) {
    const { traceId, spanId } = span;
    let traceEntry = this.db.traces.get(traceId);
    if (!traceEntry) {
      traceEntry = {
        spans: {},
        rootSpan: null,
        status: "running" /* RUNNING */,
        hasChildError: false
      };
      this.db.traces.set(traceId, traceEntry);
    }
    traceEntry.spans[spanId] = span;
    if (span.parentSpanId === null) {
      traceEntry.rootSpan = span;
    }
    this.recomputeTraceProperties(traceEntry);
  }
  /**
   * Recomputes derived trace properties from all spans
   */
  recomputeTraceProperties(traceEntry) {
    const spans = Object.values(traceEntry.spans);
    if (spans.length === 0) return;
    traceEntry.hasChildError = spans.some((s) => s.error != null);
    const rootSpan = traceEntry.rootSpan;
    if (rootSpan) {
      if (rootSpan.error != null) {
        traceEntry.status = "error" /* ERROR */;
      } else if (rootSpan.endedAt === null) {
        traceEntry.status = "running" /* RUNNING */;
      } else {
        traceEntry.status = "success" /* SUCCESS */;
      }
    } else {
      traceEntry.status = "running" /* RUNNING */;
    }
  }
  async getSpan(args) {
    const { traceId, spanId } = args;
    const traceEntry = this.db.traces.get(traceId);
    if (!traceEntry) {
      return null;
    }
    const span = traceEntry.spans[spanId];
    if (!span) {
      return null;
    }
    return { span };
  }
  async getRootSpan(args) {
    const { traceId } = args;
    const traceEntry = this.db.traces.get(traceId);
    if (!traceEntry || !traceEntry.rootSpan) {
      return null;
    }
    return { span: traceEntry.rootSpan };
  }
  async getTrace(args) {
    const { traceId } = args;
    const traceEntry = this.db.traces.get(traceId);
    if (!traceEntry) {
      return null;
    }
    const spans = Object.values(traceEntry.spans);
    if (spans.length === 0) {
      return null;
    }
    spans.sort((a, b) => a.startedAt.getTime() - b.startedAt.getTime());
    return {
      traceId,
      spans
    };
  }
  async listTraces(args) {
    const { filters, pagination, orderBy } = listTracesArgsSchema.parse(args);
    const matchingRootSpans = [];
    for (const [, traceEntry] of this.db.traces) {
      if (!traceEntry.rootSpan) continue;
      if (this.traceMatchesFilters(traceEntry, filters)) {
        matchingRootSpans.push(traceEntry.rootSpan);
      }
    }
    const { field: sortField, direction: sortDirection } = orderBy;
    matchingRootSpans.sort((a, b) => {
      if (sortField === "endedAt") {
        const aVal = a.endedAt;
        const bVal = b.endedAt;
        if (aVal == null && bVal == null) return 0;
        if (aVal == null) return sortDirection === "DESC" ? -1 : 1;
        if (bVal == null) return sortDirection === "DESC" ? 1 : -1;
        const diff = aVal.getTime() - bVal.getTime();
        return sortDirection === "DESC" ? -diff : diff;
      } else {
        const diff = a.startedAt.getTime() - b.startedAt.getTime();
        return sortDirection === "DESC" ? -diff : diff;
      }
    });
    const total = matchingRootSpans.length;
    const { page, perPage } = pagination;
    const start = page * perPage;
    const end = start + perPage;
    const paged = matchingRootSpans.slice(start, end);
    return {
      spans: toTraceSpans(paged),
      pagination: { total, page, perPage, hasMore: end < total }
    };
  }
  /**
   * Check if a trace matches all provided filters
   */
  traceMatchesFilters(traceEntry, filters) {
    if (!filters) return true;
    const rootSpan = traceEntry.rootSpan;
    if (!rootSpan) return false;
    if (filters.startedAt) {
      if (filters.startedAt.start && rootSpan.startedAt < filters.startedAt.start) {
        return false;
      }
      if (filters.startedAt.end && rootSpan.startedAt > filters.startedAt.end) {
        return false;
      }
    }
    if (filters.endedAt) {
      if (rootSpan.endedAt == null) {
        return false;
      }
      if (filters.endedAt.start && rootSpan.endedAt < filters.endedAt.start) {
        return false;
      }
      if (filters.endedAt.end && rootSpan.endedAt > filters.endedAt.end) {
        return false;
      }
    }
    if (filters.spanType !== void 0 && rootSpan.spanType !== filters.spanType) {
      return false;
    }
    if (filters.entityType !== void 0 && rootSpan.entityType !== filters.entityType) {
      return false;
    }
    if (filters.entityId !== void 0 && rootSpan.entityId !== filters.entityId) {
      return false;
    }
    if (filters.entityName !== void 0 && rootSpan.entityName !== filters.entityName) {
      return false;
    }
    if (filters.userId !== void 0 && rootSpan.userId !== filters.userId) {
      return false;
    }
    if (filters.organizationId !== void 0 && rootSpan.organizationId !== filters.organizationId) {
      return false;
    }
    if (filters.resourceId !== void 0 && rootSpan.resourceId !== filters.resourceId) {
      return false;
    }
    if (filters.runId !== void 0 && rootSpan.runId !== filters.runId) {
      return false;
    }
    if (filters.sessionId !== void 0 && rootSpan.sessionId !== filters.sessionId) {
      return false;
    }
    if (filters.threadId !== void 0 && rootSpan.threadId !== filters.threadId) {
      return false;
    }
    if (filters.requestId !== void 0 && rootSpan.requestId !== filters.requestId) {
      return false;
    }
    if (filters.environment !== void 0 && rootSpan.environment !== filters.environment) {
      return false;
    }
    if (filters.source !== void 0 && rootSpan.source !== filters.source) {
      return false;
    }
    if (filters.serviceName !== void 0 && rootSpan.serviceName !== filters.serviceName) {
      return false;
    }
    if (filters.scope != null && rootSpan.scope != null) {
      for (const [key, value] of Object.entries(filters.scope)) {
        if (!jsonValueEquals(rootSpan.scope[key], value)) {
          return false;
        }
      }
    } else if (filters.scope != null && rootSpan.scope == null) {
      return false;
    }
    if (filters.metadata != null && rootSpan.metadata != null) {
      for (const [key, value] of Object.entries(filters.metadata)) {
        if (!jsonValueEquals(rootSpan.metadata[key], value)) {
          return false;
        }
      }
    } else if (filters.metadata != null && rootSpan.metadata == null) {
      return false;
    }
    if (filters.tags != null && filters.tags.length > 0) {
      if (rootSpan.tags == null) {
        return false;
      }
      for (const tag of filters.tags) {
        if (!rootSpan.tags.includes(tag)) {
          return false;
        }
      }
    }
    if (filters.status !== void 0 && traceEntry.status !== filters.status) {
      return false;
    }
    if (filters.hasChildError !== void 0 && traceEntry.hasChildError !== filters.hasChildError) {
      return false;
    }
    return true;
  }
  async updateSpan(args) {
    const { traceId, spanId, updates } = args;
    const traceEntry = this.db.traces.get(traceId);
    if (!traceEntry) {
      throw new MastraError({
        id: "OBSERVABILITY_UPDATE_SPAN_NOT_FOUND",
        domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
        category: "SYSTEM" /* SYSTEM */,
        text: "Trace not found for span update"
      });
    }
    const span = traceEntry.spans[spanId];
    if (!span) {
      throw new MastraError({
        id: "OBSERVABILITY_UPDATE_SPAN_NOT_FOUND",
        domain: "MASTRA_OBSERVABILITY" /* MASTRA_OBSERVABILITY */,
        category: "SYSTEM" /* SYSTEM */,
        text: "Span not found for update"
      });
    }
    const updatedSpan = {
      ...span,
      ...updates,
      updatedAt: /* @__PURE__ */ new Date()
    };
    traceEntry.spans[spanId] = updatedSpan;
    if (updatedSpan.parentSpanId === null) {
      traceEntry.rootSpan = updatedSpan;
    }
    this.recomputeTraceProperties(traceEntry);
  }
  async batchUpdateSpans(args) {
    for (const record of args.records) {
      await this.updateSpan(record);
    }
  }
  async batchDeleteTraces(args) {
    for (const traceId of args.traceIds) {
      this.db.traces.delete(traceId);
    }
  }
};

// src/storage/domains/prompt-blocks/base.ts
var PromptBlocksStorage = class extends VersionedStorageDomain {
  listKey = "promptBlocks";
  versionMetadataFields = [
    "id",
    "blockId",
    "versionNumber",
    "changedFields",
    "changeMessage",
    "createdAt"
  ];
  constructor() {
    super({
      component: "STORAGE",
      name: "PROMPT_BLOCKS"
    });
  }
};

// src/storage/domains/prompt-blocks/inmemory.ts
var InMemoryPromptBlocksStorage = class extends PromptBlocksStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.promptBlocks.clear();
    this.db.promptBlockVersions.clear();
  }
  // ==========================================================================
  // Prompt Block CRUD Methods
  // ==========================================================================
  async getById(id) {
    this.logger.debug(`InMemoryPromptBlocksStorage: getById called for ${id}`);
    const block = this.db.promptBlocks.get(id);
    return block ? this.deepCopyBlock(block) : null;
  }
  async create(input) {
    const { promptBlock } = input;
    this.logger.debug(`InMemoryPromptBlocksStorage: create called for ${promptBlock.id}`);
    if (this.db.promptBlocks.has(promptBlock.id)) {
      throw new Error(`Prompt block with id ${promptBlock.id} already exists`);
    }
    const now = /* @__PURE__ */ new Date();
    const newBlock = {
      id: promptBlock.id,
      status: "draft",
      activeVersionId: void 0,
      authorId: promptBlock.authorId,
      metadata: promptBlock.metadata,
      createdAt: now,
      updatedAt: now
    };
    this.db.promptBlocks.set(promptBlock.id, newBlock);
    const { id: _id, authorId: _authorId, metadata: _metadata, ...snapshotConfig } = promptBlock;
    const versionId = crypto.randomUUID();
    await this.createVersion({
      id: versionId,
      blockId: promptBlock.id,
      versionNumber: 1,
      ...snapshotConfig,
      changedFields: Object.keys(snapshotConfig),
      changeMessage: "Initial version"
    });
    return this.deepCopyBlock(newBlock);
  }
  async update(input) {
    const { id, ...updates } = input;
    this.logger.debug(`InMemoryPromptBlocksStorage: update called for ${id}`);
    const existingBlock = this.db.promptBlocks.get(id);
    if (!existingBlock) {
      throw new Error(`Prompt block with id ${id} not found`);
    }
    const { authorId, activeVersionId, metadata, status, ...configFields } = updates;
    const configFieldNames = ["name", "description", "content", "rules"];
    const hasConfigUpdate = configFieldNames.some((field) => field in configFields);
    const updatedBlock = {
      ...existingBlock,
      ...authorId !== void 0 && { authorId },
      ...activeVersionId !== void 0 && { activeVersionId },
      ...status !== void 0 && { status },
      ...metadata !== void 0 && {
        metadata: { ...existingBlock.metadata, ...metadata }
      },
      updatedAt: /* @__PURE__ */ new Date()
    };
    if (activeVersionId !== void 0) {
      updatedBlock.status = "published";
    }
    if (hasConfigUpdate) {
      const latestVersion = await this.getLatestVersion(id);
      if (!latestVersion) {
        throw new Error(`No versions found for prompt block ${id}`);
      }
      const {
        id: _versionId,
        blockId: _blockId,
        versionNumber: _versionNumber,
        changedFields: _changedFields,
        changeMessage: _changeMessage,
        createdAt: _createdAt,
        ...latestConfig
      } = latestVersion;
      const newConfig = {
        ...latestConfig,
        ...configFields
      };
      const changedFields = configFieldNames.filter(
        (field) => field in configFields && JSON.stringify(configFields[field]) !== JSON.stringify(latestConfig[field])
      );
      if (changedFields.length > 0) {
        const newVersionId = crypto.randomUUID();
        const newVersionNumber = latestVersion.versionNumber + 1;
        await this.createVersion({
          id: newVersionId,
          blockId: id,
          versionNumber: newVersionNumber,
          ...newConfig,
          changedFields,
          changeMessage: `Updated ${changedFields.join(", ")}`
        });
      }
    }
    this.db.promptBlocks.set(id, updatedBlock);
    return this.deepCopyBlock(updatedBlock);
  }
  async delete(id) {
    this.logger.debug(`InMemoryPromptBlocksStorage: delete called for ${id}`);
    this.db.promptBlocks.delete(id);
    await this.deleteVersionsByParentId(id);
  }
  async list(args) {
    const { page = 0, perPage: perPageInput, orderBy, authorId, metadata } = args || {};
    const { field, direction } = this.parseOrderBy(orderBy);
    this.logger.debug(`InMemoryPromptBlocksStorage: list called`);
    const perPage = normalizePerPage(perPageInput, 100);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    let blocks = Array.from(this.db.promptBlocks.values());
    if (authorId !== void 0) {
      blocks = blocks.filter((block) => block.authorId === authorId);
    }
    if (metadata && Object.keys(metadata).length > 0) {
      blocks = blocks.filter((block) => {
        if (!block.metadata) return false;
        return Object.entries(metadata).every(([key, value]) => deepEqual(block.metadata[key], value));
      });
    }
    const sortedBlocks = this.sortBlocks(blocks, field, direction);
    const clonedBlocks = sortedBlocks.map((block) => this.deepCopyBlock(block));
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    return {
      promptBlocks: clonedBlocks.slice(offset, offset + perPage),
      total: clonedBlocks.length,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < clonedBlocks.length
    };
  }
  // ==========================================================================
  // Prompt Block Version Methods
  // ==========================================================================
  async createVersion(input) {
    this.logger.debug(`InMemoryPromptBlocksStorage: createVersion called for block ${input.blockId}`);
    if (this.db.promptBlockVersions.has(input.id)) {
      throw new Error(`Version with id ${input.id} already exists`);
    }
    for (const version2 of this.db.promptBlockVersions.values()) {
      if (version2.blockId === input.blockId && version2.versionNumber === input.versionNumber) {
        throw new Error(`Version number ${input.versionNumber} already exists for prompt block ${input.blockId}`);
      }
    }
    const version = {
      ...input,
      createdAt: /* @__PURE__ */ new Date()
    };
    this.db.promptBlockVersions.set(input.id, this.deepCopyVersion(version));
    return this.deepCopyVersion(version);
  }
  async getVersion(id) {
    this.logger.debug(`InMemoryPromptBlocksStorage: getVersion called for ${id}`);
    const version = this.db.promptBlockVersions.get(id);
    return version ? this.deepCopyVersion(version) : null;
  }
  async getVersionByNumber(blockId, versionNumber) {
    this.logger.debug(`InMemoryPromptBlocksStorage: getVersionByNumber called for block ${blockId}, v${versionNumber}`);
    for (const version of this.db.promptBlockVersions.values()) {
      if (version.blockId === blockId && version.versionNumber === versionNumber) {
        return this.deepCopyVersion(version);
      }
    }
    return null;
  }
  async getLatestVersion(blockId) {
    this.logger.debug(`InMemoryPromptBlocksStorage: getLatestVersion called for block ${blockId}`);
    let latest = null;
    for (const version of this.db.promptBlockVersions.values()) {
      if (version.blockId === blockId) {
        if (!latest || version.versionNumber > latest.versionNumber) {
          latest = version;
        }
      }
    }
    return latest ? this.deepCopyVersion(latest) : null;
  }
  async listVersions(input) {
    const { blockId, page = 0, perPage: perPageInput, orderBy } = input;
    const { field, direction } = this.parseVersionOrderBy(orderBy);
    this.logger.debug(`InMemoryPromptBlocksStorage: listVersions called for block ${blockId}`);
    const perPage = normalizePerPage(perPageInput, 20);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    let versions = Array.from(this.db.promptBlockVersions.values()).filter((v) => v.blockId === blockId);
    versions = this.sortVersions(versions, field, direction);
    const clonedVersions = versions.map((v) => this.deepCopyVersion(v));
    const total = clonedVersions.length;
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const paginatedVersions = clonedVersions.slice(offset, offset + perPage);
    return {
      versions: paginatedVersions,
      total,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < total
    };
  }
  async deleteVersion(id) {
    this.logger.debug(`InMemoryPromptBlocksStorage: deleteVersion called for ${id}`);
    this.db.promptBlockVersions.delete(id);
  }
  async deleteVersionsByParentId(entityId) {
    this.logger.debug(`InMemoryPromptBlocksStorage: deleteVersionsByParentId called for block ${entityId}`);
    const idsToDelete = [];
    for (const [id, version] of this.db.promptBlockVersions.entries()) {
      if (version.blockId === entityId) {
        idsToDelete.push(id);
      }
    }
    for (const id of idsToDelete) {
      this.db.promptBlockVersions.delete(id);
    }
  }
  async countVersions(blockId) {
    this.logger.debug(`InMemoryPromptBlocksStorage: countVersions called for block ${blockId}`);
    let count = 0;
    for (const version of this.db.promptBlockVersions.values()) {
      if (version.blockId === blockId) {
        count++;
      }
    }
    return count;
  }
  // ==========================================================================
  // Private Helper Methods
  // ==========================================================================
  deepCopyBlock(block) {
    return {
      ...block,
      metadata: block.metadata ? { ...block.metadata } : block.metadata
    };
  }
  deepCopyVersion(version) {
    return {
      ...version,
      rules: version.rules ? JSON.parse(JSON.stringify(version.rules)) : version.rules,
      changedFields: version.changedFields ? [...version.changedFields] : version.changedFields
    };
  }
  sortBlocks(blocks, field, direction) {
    return blocks.sort((a, b) => {
      const aValue = a[field].getTime();
      const bValue = b[field].getTime();
      return direction === "ASC" ? aValue - bValue : bValue - aValue;
    });
  }
  sortVersions(versions, field, direction) {
    return versions.sort((a, b) => {
      let aVal;
      let bVal;
      if (field === "createdAt") {
        aVal = a.createdAt.getTime();
        bVal = b.createdAt.getTime();
      } else {
        aVal = a.versionNumber;
        bVal = b.versionNumber;
      }
      return direction === "ASC" ? aVal - bVal : bVal - aVal;
    });
  }
};

// src/storage/domains/scorer-definitions/base.ts
var ScorerDefinitionsStorage = class extends VersionedStorageDomain {
  listKey = "scorerDefinitions";
  versionMetadataFields = [
    "id",
    "scorerDefinitionId",
    "versionNumber",
    "changedFields",
    "changeMessage",
    "createdAt"
  ];
  constructor() {
    super({
      component: "STORAGE",
      name: "SCORER_DEFINITIONS"
    });
  }
};

// src/storage/domains/scorer-definitions/inmemory.ts
var InMemoryScorerDefinitionsStorage = class extends ScorerDefinitionsStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.scorerDefinitions.clear();
    this.db.scorerDefinitionVersions.clear();
  }
  // ==========================================================================
  // Scorer Definition CRUD Methods
  // ==========================================================================
  async getById(id) {
    this.logger.debug(`InMemoryScorerDefinitionsStorage: getById called for ${id}`);
    const scorer = this.db.scorerDefinitions.get(id);
    return scorer ? this.deepCopyScorer(scorer) : null;
  }
  async create(input) {
    const { scorerDefinition } = input;
    this.logger.debug(`InMemoryScorerDefinitionsStorage: create called for ${scorerDefinition.id}`);
    if (this.db.scorerDefinitions.has(scorerDefinition.id)) {
      throw new Error(`Scorer definition with id ${scorerDefinition.id} already exists`);
    }
    const now = /* @__PURE__ */ new Date();
    const newScorer = {
      id: scorerDefinition.id,
      status: "draft",
      activeVersionId: void 0,
      authorId: scorerDefinition.authorId,
      metadata: scorerDefinition.metadata,
      createdAt: now,
      updatedAt: now
    };
    this.db.scorerDefinitions.set(scorerDefinition.id, newScorer);
    const { id: _id, authorId: _authorId, metadata: _metadata, ...snapshotConfig } = scorerDefinition;
    const versionId = crypto.randomUUID();
    await this.createVersion({
      id: versionId,
      scorerDefinitionId: scorerDefinition.id,
      versionNumber: 1,
      ...snapshotConfig,
      changedFields: Object.keys(snapshotConfig),
      changeMessage: "Initial version"
    });
    return this.deepCopyScorer(newScorer);
  }
  async update(input) {
    const { id, ...updates } = input;
    this.logger.debug(`InMemoryScorerDefinitionsStorage: update called for ${id}`);
    const existingScorer = this.db.scorerDefinitions.get(id);
    if (!existingScorer) {
      throw new Error(`Scorer definition with id ${id} not found`);
    }
    const { authorId, activeVersionId, metadata, status, ...configFields } = updates;
    const configFieldNames = [
      "name",
      "description",
      "type",
      "model",
      "instructions",
      "scoreRange",
      "presetConfig",
      "defaultSampling"
    ];
    const hasConfigUpdate = configFieldNames.some((field) => field in configFields);
    const updatedScorer = {
      ...existingScorer,
      ...authorId !== void 0 && { authorId },
      ...activeVersionId !== void 0 && { activeVersionId },
      ...status !== void 0 && { status },
      ...metadata !== void 0 && {
        metadata: { ...existingScorer.metadata, ...metadata }
      },
      updatedAt: /* @__PURE__ */ new Date()
    };
    if (activeVersionId !== void 0) {
      updatedScorer.status = "published";
    }
    if (hasConfigUpdate) {
      const latestVersion = await this.getLatestVersion(id);
      if (!latestVersion) {
        throw new Error(`No versions found for scorer definition ${id}`);
      }
      const {
        id: _versionId,
        scorerDefinitionId: _scorerDefinitionId,
        versionNumber: _versionNumber,
        changedFields: _changedFields,
        changeMessage: _changeMessage,
        createdAt: _createdAt,
        ...latestConfig
      } = latestVersion;
      const newConfig = {
        ...latestConfig,
        ...configFields
      };
      const changedFields = configFieldNames.filter(
        (field) => field in configFields && JSON.stringify(configFields[field]) !== JSON.stringify(latestConfig[field])
      );
      if (changedFields.length > 0) {
        const newVersionId = crypto.randomUUID();
        const newVersionNumber = latestVersion.versionNumber + 1;
        await this.createVersion({
          id: newVersionId,
          scorerDefinitionId: id,
          versionNumber: newVersionNumber,
          ...newConfig,
          changedFields,
          changeMessage: `Updated ${changedFields.join(", ")}`
        });
      }
    }
    this.db.scorerDefinitions.set(id, updatedScorer);
    return this.deepCopyScorer(updatedScorer);
  }
  async delete(id) {
    this.logger.debug(`InMemoryScorerDefinitionsStorage: delete called for ${id}`);
    this.db.scorerDefinitions.delete(id);
    await this.deleteVersionsByParentId(id);
  }
  async list(args) {
    const { page = 0, perPage: perPageInput, orderBy, authorId, metadata } = args || {};
    const { field, direction } = this.parseOrderBy(orderBy);
    this.logger.debug(`InMemoryScorerDefinitionsStorage: list called`);
    const perPage = normalizePerPage(perPageInput, 100);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    let scorers = Array.from(this.db.scorerDefinitions.values());
    if (authorId !== void 0) {
      scorers = scorers.filter((scorer) => scorer.authorId === authorId);
    }
    if (metadata && Object.keys(metadata).length > 0) {
      scorers = scorers.filter((scorer) => {
        if (!scorer.metadata) return false;
        return Object.entries(metadata).every(([key, value]) => deepEqual(scorer.metadata[key], value));
      });
    }
    const sortedScorers = this.sortScorers(scorers, field, direction);
    const clonedScorers = sortedScorers.map((scorer) => this.deepCopyScorer(scorer));
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    return {
      scorerDefinitions: clonedScorers.slice(offset, offset + perPage),
      total: clonedScorers.length,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < clonedScorers.length
    };
  }
  // ==========================================================================
  // Scorer Definition Version Methods
  // ==========================================================================
  async createVersion(input) {
    this.logger.debug(
      `InMemoryScorerDefinitionsStorage: createVersion called for scorer definition ${input.scorerDefinitionId}`
    );
    if (this.db.scorerDefinitionVersions.has(input.id)) {
      throw new Error(`Version with id ${input.id} already exists`);
    }
    for (const version2 of this.db.scorerDefinitionVersions.values()) {
      if (version2.scorerDefinitionId === input.scorerDefinitionId && version2.versionNumber === input.versionNumber) {
        throw new Error(
          `Version number ${input.versionNumber} already exists for scorer definition ${input.scorerDefinitionId}`
        );
      }
    }
    const version = {
      ...input,
      createdAt: /* @__PURE__ */ new Date()
    };
    this.db.scorerDefinitionVersions.set(input.id, this.deepCopyVersion(version));
    return this.deepCopyVersion(version);
  }
  async getVersion(id) {
    this.logger.debug(`InMemoryScorerDefinitionsStorage: getVersion called for ${id}`);
    const version = this.db.scorerDefinitionVersions.get(id);
    return version ? this.deepCopyVersion(version) : null;
  }
  async getVersionByNumber(scorerDefinitionId, versionNumber) {
    this.logger.debug(
      `InMemoryScorerDefinitionsStorage: getVersionByNumber called for scorer definition ${scorerDefinitionId}, v${versionNumber}`
    );
    for (const version of this.db.scorerDefinitionVersions.values()) {
      if (version.scorerDefinitionId === scorerDefinitionId && version.versionNumber === versionNumber) {
        return this.deepCopyVersion(version);
      }
    }
    return null;
  }
  async getLatestVersion(scorerDefinitionId) {
    this.logger.debug(
      `InMemoryScorerDefinitionsStorage: getLatestVersion called for scorer definition ${scorerDefinitionId}`
    );
    let latest = null;
    for (const version of this.db.scorerDefinitionVersions.values()) {
      if (version.scorerDefinitionId === scorerDefinitionId) {
        if (!latest || version.versionNumber > latest.versionNumber) {
          latest = version;
        }
      }
    }
    return latest ? this.deepCopyVersion(latest) : null;
  }
  async listVersions(input) {
    const { scorerDefinitionId, page = 0, perPage: perPageInput, orderBy } = input;
    const { field, direction } = this.parseVersionOrderBy(orderBy);
    this.logger.debug(
      `InMemoryScorerDefinitionsStorage: listVersions called for scorer definition ${scorerDefinitionId}`
    );
    const perPage = normalizePerPage(perPageInput, 20);
    if (page < 0) {
      throw new Error("page must be >= 0");
    }
    const maxOffset = Number.MAX_SAFE_INTEGER / 2;
    if (page * perPage > maxOffset) {
      throw new Error("page value too large");
    }
    let versions = Array.from(this.db.scorerDefinitionVersions.values()).filter(
      (v) => v.scorerDefinitionId === scorerDefinitionId
    );
    versions = this.sortVersions(versions, field, direction);
    const clonedVersions = versions.map((v) => this.deepCopyVersion(v));
    const total = clonedVersions.length;
    const { offset, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const paginatedVersions = clonedVersions.slice(offset, offset + perPage);
    return {
      versions: paginatedVersions,
      total,
      page,
      perPage: perPageForResponse,
      hasMore: offset + perPage < total
    };
  }
  async deleteVersion(id) {
    this.logger.debug(`InMemoryScorerDefinitionsStorage: deleteVersion called for ${id}`);
    this.db.scorerDefinitionVersions.delete(id);
  }
  async deleteVersionsByParentId(entityId) {
    this.logger.debug(
      `InMemoryScorerDefinitionsStorage: deleteVersionsByParentId called for scorer definition ${entityId}`
    );
    const idsToDelete = [];
    for (const [id, version] of this.db.scorerDefinitionVersions.entries()) {
      if (version.scorerDefinitionId === entityId) {
        idsToDelete.push(id);
      }
    }
    for (const id of idsToDelete) {
      this.db.scorerDefinitionVersions.delete(id);
    }
  }
  async countVersions(scorerDefinitionId) {
    this.logger.debug(
      `InMemoryScorerDefinitionsStorage: countVersions called for scorer definition ${scorerDefinitionId}`
    );
    let count = 0;
    for (const version of this.db.scorerDefinitionVersions.values()) {
      if (version.scorerDefinitionId === scorerDefinitionId) {
        count++;
      }
    }
    return count;
  }
  // ==========================================================================
  // Private Helper Methods
  // ==========================================================================
  deepCopyScorer(scorer) {
    return {
      ...scorer,
      metadata: scorer.metadata ? { ...scorer.metadata } : scorer.metadata
    };
  }
  deepCopyVersion(version) {
    return {
      ...version,
      model: version.model ? JSON.parse(JSON.stringify(version.model)) : version.model,
      scoreRange: version.scoreRange ? JSON.parse(JSON.stringify(version.scoreRange)) : version.scoreRange,
      presetConfig: version.presetConfig ? JSON.parse(JSON.stringify(version.presetConfig)) : version.presetConfig,
      defaultSampling: version.defaultSampling ? JSON.parse(JSON.stringify(version.defaultSampling)) : version.defaultSampling,
      changedFields: version.changedFields ? [...version.changedFields] : version.changedFields
    };
  }
  sortScorers(scorers, field, direction) {
    return scorers.sort((a, b) => {
      const aValue = a[field].getTime();
      const bValue = b[field].getTime();
      return direction === "ASC" ? aValue - bValue : bValue - aValue;
    });
  }
  sortVersions(versions, field, direction) {
    return versions.sort((a, b) => {
      let aVal;
      let bVal;
      if (field === "createdAt") {
        aVal = a.createdAt.getTime();
        bVal = b.createdAt.getTime();
      } else {
        aVal = a.versionNumber;
        bVal = b.versionNumber;
      }
      return direction === "ASC" ? aVal - bVal : bVal - aVal;
    });
  }
};

// src/storage/domains/scores/base.ts
var ScoresStorage = class extends StorageDomain {
  constructor() {
    super({
      component: "STORAGE",
      name: "SCORES"
    });
  }
  async dangerouslyClearAll() {
  }
  async listScoresBySpan({
    traceId,
    spanId,
    pagination: _pagination
  }) {
    throw new MastraError({
      id: "SCORES_STORAGE_GET_SCORES_BY_SPAN_NOT_IMPLEMENTED",
      domain: "STORAGE" /* STORAGE */,
      category: "SYSTEM" /* SYSTEM */,
      details: { traceId, spanId }
    });
  }
};

// src/storage/domains/scores/inmemory.ts
var ScoresInMemory = class extends ScoresStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.scores.clear();
  }
  async getScoreById({ id }) {
    return this.db.scores.get(id) ?? null;
  }
  async saveScore(score) {
    const newScore = { id: crypto.randomUUID(), createdAt: /* @__PURE__ */ new Date(), updatedAt: /* @__PURE__ */ new Date(), ...score };
    this.db.scores.set(newScore.id, newScore);
    return { score: newScore };
  }
  async listScoresByScorerId({
    scorerId,
    pagination,
    entityId,
    entityType,
    source
  }) {
    const scores = Array.from(this.db.scores.values()).filter((score) => {
      let baseFilter = score.scorerId === scorerId;
      if (entityId) {
        baseFilter = baseFilter && score.entityId === entityId;
      }
      if (entityType) {
        baseFilter = baseFilter && score.entityType === entityType;
      }
      if (source) {
        baseFilter = baseFilter && score.source === source;
      }
      return baseFilter;
    });
    const { page, perPage: perPageInput } = pagination;
    const perPage = normalizePerPage(perPageInput, Number.MAX_SAFE_INTEGER);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? scores.length : start + perPage;
    return {
      scores: scores.slice(start, end),
      pagination: {
        total: scores.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : scores.length > end
      }
    };
  }
  async listScoresByRunId({
    runId,
    pagination
  }) {
    const scores = Array.from(this.db.scores.values()).filter((score) => score.runId === runId);
    const { page, perPage: perPageInput } = pagination;
    const perPage = normalizePerPage(perPageInput, Number.MAX_SAFE_INTEGER);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? scores.length : start + perPage;
    return {
      scores: scores.slice(start, end),
      pagination: {
        total: scores.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : scores.length > end
      }
    };
  }
  async listScoresByEntityId({
    entityId,
    entityType,
    pagination
  }) {
    const scores = Array.from(this.db.scores.values()).filter((score) => {
      const baseFilter = score.entityId === entityId && score.entityType === entityType;
      return baseFilter;
    });
    const { page, perPage: perPageInput } = pagination;
    const perPage = normalizePerPage(perPageInput, Number.MAX_SAFE_INTEGER);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? scores.length : start + perPage;
    return {
      scores: scores.slice(start, end),
      pagination: {
        total: scores.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : scores.length > end
      }
    };
  }
  async listScoresBySpan({
    traceId,
    spanId,
    pagination
  }) {
    const scores = Array.from(this.db.scores.values()).filter(
      (score) => score.traceId === traceId && score.spanId === spanId
    );
    scores.sort((a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime());
    const { page, perPage: perPageInput } = pagination;
    const perPage = normalizePerPage(perPageInput, Number.MAX_SAFE_INTEGER);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? scores.length : start + perPage;
    return {
      scores: scores.slice(start, end),
      pagination: {
        total: scores.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : scores.length > end
      }
    };
  }
};

// src/workflows/evented/types.ts
var PENDING_MARKER_KEY = "__mastra_pending__";
function createPendingMarker() {
  return { [PENDING_MARKER_KEY]: true };
}
function isPendingMarker(val) {
  return val !== null && typeof val === "object" && PENDING_MARKER_KEY in val && val[PENDING_MARKER_KEY] === true;
}

// src/storage/domains/workflows/base.ts
var WorkflowsStorage = class extends StorageDomain {
  constructor() {
    super({
      component: "STORAGE",
      name: "WORKFLOWS"
    });
  }
};

// src/storage/domains/workflows/inmemory.ts
var WorkflowsInMemory = class extends WorkflowsStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.workflows.clear();
  }
  getWorkflowKey(workflowName, runId) {
    return `${workflowName}-${runId}`;
  }
  async updateWorkflowResults({
    workflowName,
    runId,
    stepId,
    result,
    requestContext
  }) {
    this.logger.debug(`WorkflowsInMemory: updateWorkflowResults called for ${workflowName} ${runId} ${stepId}`, result);
    const key = this.getWorkflowKey(workflowName, runId);
    const run = this.db.workflows.get(key);
    if (!run) {
      return {};
    }
    let snapshot;
    if (!run.snapshot) {
      snapshot = {
        context: {},
        activePaths: [],
        activeStepsPath: {},
        timestamp: Date.now(),
        suspendedPaths: {},
        resumeLabels: {},
        serializedStepGraph: [],
        value: {},
        waitingPaths: {},
        status: "pending",
        runId: run.run_id
      };
      this.db.workflows.set(key, {
        ...run,
        snapshot
      });
    } else {
      snapshot = typeof run.snapshot === "string" ? JSON.parse(run.snapshot) : run.snapshot;
    }
    if (!snapshot || !snapshot?.context) {
      throw new Error(`Snapshot not found for runId ${runId}`);
    }
    const existingResult = snapshot.context[stepId];
    if (existingResult && "output" in existingResult && Array.isArray(existingResult.output) && result && typeof result === "object" && "output" in result && Array.isArray(result.output)) {
      const existingOutput = existingResult.output;
      const newOutput = result.output;
      const mergedOutput = [...existingOutput];
      for (let i = 0; i < Math.max(existingOutput.length, newOutput.length); i++) {
        if (i < newOutput.length) {
          const newVal = newOutput[i];
          if (isPendingMarker(newVal)) {
            mergedOutput[i] = null;
          } else if (newVal !== null) {
            mergedOutput[i] = newVal;
          }
        }
      }
      snapshot.context[stepId] = {
        ...existingResult,
        ...result,
        output: mergedOutput
      };
    } else {
      snapshot.context[stepId] = result;
    }
    snapshot.requestContext = { ...snapshot.requestContext, ...requestContext };
    this.db.workflows.set(key, {
      ...run,
      snapshot
    });
    return JSON.parse(JSON.stringify(snapshot.context));
  }
  async updateWorkflowState({
    workflowName,
    runId,
    opts
  }) {
    const key = this.getWorkflowKey(workflowName, runId);
    const run = this.db.workflows.get(key);
    if (!run) {
      return;
    }
    let snapshot;
    if (!run.snapshot) {
      snapshot = {
        context: {},
        activePaths: [],
        activeStepsPath: {},
        timestamp: Date.now(),
        suspendedPaths: {},
        resumeLabels: {},
        serializedStepGraph: [],
        value: {},
        waitingPaths: {},
        status: "pending",
        runId: run.run_id
      };
      this.db.workflows.set(key, {
        ...run,
        snapshot
      });
    } else {
      snapshot = typeof run.snapshot === "string" ? JSON.parse(run.snapshot) : run.snapshot;
    }
    if (!snapshot || !snapshot?.context) {
      throw new Error(`Snapshot not found for runId ${runId}`);
    }
    snapshot = { ...snapshot, ...opts };
    this.db.workflows.set(key, {
      ...run,
      snapshot
    });
    return snapshot;
  }
  async persistWorkflowSnapshot({
    workflowName,
    runId,
    resourceId,
    snapshot,
    createdAt,
    updatedAt
  }) {
    const key = this.getWorkflowKey(workflowName, runId);
    const now = /* @__PURE__ */ new Date();
    const data = {
      workflow_name: workflowName,
      run_id: runId,
      resourceId,
      snapshot,
      createdAt: createdAt ?? now,
      updatedAt: updatedAt ?? now
    };
    this.db.workflows.set(key, data);
  }
  async loadWorkflowSnapshot({
    workflowName,
    runId
  }) {
    this.logger.debug("Loading workflow snapshot", { workflowName, runId });
    const key = this.getWorkflowKey(workflowName, runId);
    const run = this.db.workflows.get(key);
    if (!run) {
      return null;
    }
    const snapshot = typeof run.snapshot === "string" ? JSON.parse(run.snapshot) : run.snapshot;
    return snapshot ? JSON.parse(JSON.stringify(snapshot)) : null;
  }
  async listWorkflowRuns({
    workflowName,
    fromDate,
    toDate,
    perPage,
    page,
    resourceId,
    status
  } = {}) {
    if (page !== void 0 && page < 0) {
      throw new Error("page must be >= 0");
    }
    let runs = Array.from(this.db.workflows.values());
    if (workflowName) runs = runs.filter((run) => run.workflow_name === workflowName);
    if (status) {
      runs = runs.filter((run) => {
        let snapshot = run?.snapshot;
        if (!snapshot) {
          return false;
        }
        if (typeof snapshot === "string") {
          try {
            snapshot = JSON.parse(snapshot);
          } catch {
            return false;
          }
        } else {
          snapshot = JSON.parse(JSON.stringify(snapshot));
        }
        return snapshot.status === status;
      });
    }
    if (fromDate && toDate) {
      runs = runs.filter(
        (run) => new Date(run.createdAt).getTime() >= fromDate.getTime() && new Date(run.createdAt).getTime() <= toDate.getTime()
      );
    } else if (fromDate) {
      runs = runs.filter((run) => new Date(run.createdAt).getTime() >= fromDate.getTime());
    } else if (toDate) {
      runs = runs.filter((run) => new Date(run.createdAt).getTime() <= toDate.getTime());
    }
    if (resourceId) runs = runs.filter((run) => run.resourceId === resourceId);
    const total = runs.length;
    runs.sort((a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime());
    if (perPage !== void 0 && page !== void 0) {
      const normalizedPerPage = normalizePerPage(perPage, Number.MAX_SAFE_INTEGER);
      const offset = page * normalizedPerPage;
      const start = offset;
      const end = start + normalizedPerPage;
      runs = runs.slice(start, end);
    }
    const parsedRuns = runs.map((run) => ({
      ...run,
      snapshot: typeof run.snapshot === "string" ? JSON.parse(run.snapshot) : JSON.parse(JSON.stringify(run.snapshot)),
      createdAt: new Date(run.createdAt),
      updatedAt: new Date(run.updatedAt),
      runId: run.run_id,
      workflowName: run.workflow_name,
      resourceId: run.resourceId
    }));
    return { runs: parsedRuns, total };
  }
  async getWorkflowRunById({
    runId,
    workflowName
  }) {
    const runs = Array.from(this.db.workflows.values()).filter((r) => r.run_id === runId);
    let run = runs.find((r) => r.workflow_name === workflowName);
    if (!run) return null;
    const parsedRun = {
      ...run,
      snapshot: typeof run.snapshot === "string" ? JSON.parse(run.snapshot) : JSON.parse(JSON.stringify(run.snapshot)),
      createdAt: new Date(run.createdAt),
      updatedAt: new Date(run.updatedAt),
      runId: run.run_id,
      workflowName: run.workflow_name,
      resourceId: run.resourceId
    };
    return parsedRun;
  }
  async deleteWorkflowRunById({ runId, workflowName }) {
    const key = this.getWorkflowKey(workflowName, runId);
    this.db.workflows.delete(key);
  }
};

// src/storage/mock.ts
var InMemoryStore = class extends MastraCompositeStore {
  stores;
  /**
   * Internal database layer shared across all domains.
   * This is an implementation detail - domains interact with this
   * rather than managing their own data structures.
   */
  #db;
  constructor({ id = "in-memory" } = {}) {
    super({ id, name: "InMemoryStorage" });
    this.hasInitialized = Promise.resolve(true);
    this.#db = new InMemoryDB();
    this.stores = {
      memory: new InMemoryMemory({ db: this.#db }),
      workflows: new WorkflowsInMemory({ db: this.#db }),
      scores: new ScoresInMemory({ db: this.#db }),
      observability: new ObservabilityInMemory({ db: this.#db }),
      agents: new InMemoryAgentsStorage({ db: this.#db }),
      promptBlocks: new InMemoryPromptBlocksStorage({ db: this.#db }),
      scorerDefinitions: new InMemoryScorerDefinitionsStorage({ db: this.#db }),
      mcpClients: new InMemoryMCPClientsStorage({ db: this.#db })
    };
  }
  /**
   * Clears all data from the in-memory database.
   * Useful for testing.
   * @deprecated Use dangerouslyClearAll() on individual domains instead.
   */
  clear() {
    this.#db.clear();
  }
};
var MockStore = InMemoryStore;

// src/storage/domains/operations/base.ts
var StoreOperations = class extends MastraBase {
  constructor() {
    super({
      component: "STORAGE",
      name: "OPERATIONS"
    });
  }
  getSqlType(type) {
    switch (type) {
      case "text":
        return "TEXT";
      case "timestamp":
        return "TIMESTAMP";
      case "float":
        return "FLOAT";
      case "integer":
        return "INTEGER";
      case "bigint":
        return "BIGINT";
      case "jsonb":
        return "JSONB";
      default:
        return "TEXT";
    }
  }
  getDefaultValue(type) {
    switch (type) {
      case "text":
      case "uuid":
        return "DEFAULT ''";
      case "timestamp":
        return "DEFAULT '1970-01-01 00:00:00'";
      case "integer":
      case "bigint":
      case "float":
        return "DEFAULT 0";
      case "jsonb":
        return "DEFAULT '{}'";
      default:
        return "DEFAULT ''";
    }
  }
  /**
   * DATABASE INDEX MANAGEMENT
   * Optional methods for database index management.
   * Storage adapters can override these to provide index management capabilities.
   */
  /**
   * Creates a database index on specified columns
   * @throws {MastraError} if not supported by the storage adapter
   */
  async createIndex(_options) {
    throw new MastraError({
      id: "MASTRA_STORAGE_CREATE_INDEX_NOT_SUPPORTED",
      domain: "STORAGE" /* STORAGE */,
      category: "SYSTEM" /* SYSTEM */,
      text: `Index management is not supported by this storage adapter`
    });
  }
  /**
   * Drops a database index by name
   * @throws {MastraError} if not supported by the storage adapter
   */
  async dropIndex(_indexName) {
    throw new MastraError({
      id: "MASTRA_STORAGE_DROP_INDEX_NOT_SUPPORTED",
      domain: "STORAGE" /* STORAGE */,
      category: "SYSTEM" /* SYSTEM */,
      text: `Index management is not supported by this storage adapter`
    });
  }
  /**
   * Lists database indexes for a table or all tables
   * @throws {MastraError} if not supported by the storage adapter
   */
  async listIndexes(_tableName) {
    throw new MastraError({
      id: "MASTRA_STORAGE_LIST_INDEXES_NOT_SUPPORTED",
      domain: "STORAGE" /* STORAGE */,
      category: "SYSTEM" /* SYSTEM */,
      text: `Index management is not supported by this storage adapter`
    });
  }
  /**
   * Gets detailed statistics for a specific index
   * @throws {MastraError} if not supported by the storage adapter
   */
  async describeIndex(_indexName) {
    throw new MastraError({
      id: "MASTRA_STORAGE_DESCRIBE_INDEX_NOT_SUPPORTED",
      domain: "STORAGE" /* STORAGE */,
      category: "SYSTEM" /* SYSTEM */,
      text: `Index management is not supported by this storage adapter`
    });
  }
  /**
   * Returns definitions for automatic performance indexes
   * Storage adapters can override this to define indexes that should be created during initialization
   * @returns Array of index definitions to create automatically
   */
  getAutomaticIndexDefinitions() {
    return [];
  }
};

// src/storage/domains/operations/inmemory.ts
var StoreOperationsInMemory = class extends StoreOperations {
  data;
  constructor() {
    super();
    this.data = {
      mastra_workflow_snapshot: /* @__PURE__ */ new Map(),
      mastra_messages: /* @__PURE__ */ new Map(),
      mastra_threads: /* @__PURE__ */ new Map(),
      mastra_traces: /* @__PURE__ */ new Map(),
      mastra_resources: /* @__PURE__ */ new Map(),
      mastra_scorers: /* @__PURE__ */ new Map(),
      mastra_ai_spans: /* @__PURE__ */ new Map(),
      mastra_agents: /* @__PURE__ */ new Map(),
      mastra_agent_versions: /* @__PURE__ */ new Map(),
      mastra_observational_memory: /* @__PURE__ */ new Map(),
      mastra_prompt_blocks: /* @__PURE__ */ new Map(),
      mastra_prompt_block_versions: /* @__PURE__ */ new Map(),
      mastra_scorer_definitions: /* @__PURE__ */ new Map(),
      mastra_scorer_definition_versions: /* @__PURE__ */ new Map(),
      mastra_mcp_clients: /* @__PURE__ */ new Map(),
      mastra_mcp_client_versions: /* @__PURE__ */ new Map(),
      mastra_datasets: /* @__PURE__ */ new Map(),
      mastra_dataset_items: /* @__PURE__ */ new Map(),
      mastra_dataset_versions: /* @__PURE__ */ new Map(),
      mastra_experiments: /* @__PURE__ */ new Map(),
      mastra_experiment_results: /* @__PURE__ */ new Map()
    };
  }
  getDatabase() {
    return this.data;
  }
  async insert({ tableName, record }) {
    const table = this.data[tableName];
    let key = record.id;
    if ([TABLE_WORKFLOW_SNAPSHOT].includes(tableName) && !record.id && record.run_id) {
      key = record.workflow_name ? `${record.workflow_name}-${record.run_id}` : record.run_id;
      record.id = key;
    } else if (!record.id) {
      key = `auto-${Date.now()}-${Math.random()}`;
      record.id = key;
    }
    table.set(key, record);
  }
  async batchInsert({ tableName, records }) {
    const table = this.data[tableName];
    for (const record of records) {
      let key = record.id;
      if ([TABLE_WORKFLOW_SNAPSHOT].includes(tableName) && !record.id && record.run_id) {
        key = record.run_id;
        record.id = key;
      } else if (!record.id) {
        key = `auto-${Date.now()}-${Math.random()}`;
        record.id = key;
      }
      table.set(key, record);
    }
  }
  async load({ tableName, keys }) {
    this.logger.debug(`MockStore: load called for ${tableName} with keys`, keys);
    const table = this.data[tableName];
    const records = Array.from(table.values());
    return records.filter((record) => Object.keys(keys).every((key) => record[key] === keys[key]))?.[0];
  }
  async createTable({
    tableName,
    schema
  }) {
    this.logger.debug(`MockStore: createTable called for ${tableName} with schema`, schema);
    this.data[tableName] = /* @__PURE__ */ new Map();
  }
  async clearTable({ tableName }) {
    this.logger.debug(`MockStore: clearTable called for ${tableName}`);
    this.data[tableName].clear();
  }
  async dropTable({ tableName }) {
    this.logger.debug(`MockStore: dropTable called for ${tableName}`);
    this.data[tableName].clear();
  }
  async alterTable({
    tableName,
    schema
  }) {
    this.logger.debug(`MockStore: alterTable called for ${tableName} with schema`, schema);
  }
  async hasColumn(table, column) {
    this.logger.debug(`MockStore: hasColumn called for ${table} with column ${column}`);
    return true;
  }
};

// src/datasets/validation/errors.ts
var SchemaValidationError = class extends Error {
  constructor(field, errors) {
    const summary = errors.slice(0, 3).map((e) => e.message).join("; ");
    super(`Validation failed for ${field}: ${summary}`);
    this.field = field;
    this.errors = errors;
    this.name = "SchemaValidationError";
  }
};
var SchemaUpdateValidationError = class extends Error {
  constructor(failingItems) {
    const count = failingItems.length;
    super(`Cannot update schema: ${count} existing item(s) would fail validation`);
    this.failingItems = failingItems;
    this.name = "SchemaUpdateValidationError";
  }
};

// src/datasets/validation/validator.ts
function resolveZodSchema(zodString) {
  return Function("z", `"use strict";return (${zodString});`)(z);
}
var SchemaValidator = class {
  cache = /* @__PURE__ */ new Map();
  /** Get or compile validator for schema */
  getValidator(schema, cacheKey) {
    let zodSchema = this.cache.get(cacheKey);
    if (!zodSchema) {
      const zodString = jsonSchemaToZod(schema);
      zodSchema = resolveZodSchema(zodString);
      this.cache.set(cacheKey, zodSchema);
    }
    return zodSchema;
  }
  /** Clear cached validator (call when schema changes) */
  clearCache(cacheKey) {
    this.cache.delete(cacheKey);
  }
  /** Validate data against schema */
  validate(data, schema, field, cacheKey) {
    const zodSchema = this.getValidator(schema, cacheKey);
    const result = zodSchema.safeParse(data);
    if (!result.success) {
      throw new SchemaValidationError(field, this.formatErrors(result.error));
    }
  }
  /** Validate multiple items, returning valid/invalid split */
  validateBatch(items, inputSchema, outputSchema, cacheKeyPrefix, maxErrors = 10) {
    const result = { valid: [], invalid: [] };
    const inputValidator = inputSchema ? this.getValidator(inputSchema, `${cacheKeyPrefix}:input`) : null;
    const outputValidator = outputSchema ? this.getValidator(outputSchema, `${cacheKeyPrefix}:output`) : null;
    for (const [i, item] of items.entries()) {
      let hasError = false;
      if (inputValidator) {
        const inputResult = inputValidator.safeParse(item.input);
        if (!inputResult.success) {
          result.invalid.push({
            index: i,
            data: item,
            field: "input",
            errors: this.formatErrors(inputResult.error)
          });
          hasError = true;
          if (result.invalid.length >= maxErrors) break;
        }
      }
      if (!hasError && outputValidator && item.groundTruth !== void 0) {
        const outputResult = outputValidator.safeParse(item.groundTruth);
        if (!outputResult.success) {
          result.invalid.push({
            index: i,
            data: item,
            field: "groundTruth",
            errors: this.formatErrors(outputResult.error)
          });
          hasError = true;
          if (result.invalid.length >= maxErrors) break;
        }
      }
      if (!hasError) {
        result.valid.push({ index: i, data: item });
      }
    }
    return result;
  }
  /** Format Zod errors to FieldError array */
  formatErrors(error) {
    return error.issues.slice(0, 5).map((issue) => ({
      // Convert Zod path array to JSON Pointer string
      path: issue.path.length > 0 ? "/" + issue.path.join("/") : "/",
      code: issue.code,
      message: issue.message
    }));
  }
};
var validatorInstance = null;
function getSchemaValidator() {
  if (!validatorInstance) {
    validatorInstance = new SchemaValidator();
  }
  return validatorInstance;
}
function createValidator() {
  return new SchemaValidator();
}

// src/storage/domains/datasets/base.ts
var DatasetsStorage = class extends StorageDomain {
  constructor() {
    super({
      component: "STORAGE",
      name: "DATASETS"
    });
  }
  async dangerouslyClearAll() {
  }
  /**
   * Update a dataset. Validates existing items against new schemas if schemas are changing.
   * Subclasses implement _doUpdateDataset for actual storage operation.
   */
  async updateDataset(args) {
    const existing = await this.getDatasetById({ id: args.id });
    if (!existing) {
      throw new Error(`Dataset not found: ${args.id}`);
    }
    const inputSchemaChanging = args.inputSchema !== void 0 && JSON.stringify(args.inputSchema) !== JSON.stringify(existing.inputSchema);
    const groundTruthSchemaChanging = args.groundTruthSchema !== void 0 && JSON.stringify(args.groundTruthSchema) !== JSON.stringify(existing.groundTruthSchema);
    if (inputSchemaChanging || groundTruthSchemaChanging) {
      const itemsResult = await this.listItems({
        datasetId: args.id,
        pagination: { page: 0, perPage: false }
        // Get all items
      });
      const items = itemsResult.items;
      if (items.length > 0) {
        const validator = getSchemaValidator();
        const newInputSchema = args.inputSchema !== void 0 ? args.inputSchema : existing.inputSchema;
        const newOutputSchema = args.groundTruthSchema !== void 0 ? args.groundTruthSchema : existing.groundTruthSchema;
        const result = validator.validateBatch(
          items.map((i) => ({ input: i.input, groundTruth: i.groundTruth })),
          newInputSchema,
          newOutputSchema,
          `dataset:${args.id}:schema-update`,
          10
          // Max 10 errors to report
        );
        if (result.invalid.length > 0) {
          throw new SchemaUpdateValidationError(result.invalid);
        }
        validator.clearCache(`dataset:${args.id}:input`);
        validator.clearCache(`dataset:${args.id}:output`);
      }
    }
    return this._doUpdateDataset(args);
  }
  /**
   * Add an item to a dataset. Validates input/groundTruth against dataset schemas.
   * Subclasses implement _doAddItem which handles SCD-2 versioning internally.
   */
  async addItem(args) {
    const dataset = await this.getDatasetById({ id: args.datasetId });
    if (!dataset) {
      throw new Error(`Dataset not found: ${args.datasetId}`);
    }
    const validator = getSchemaValidator();
    const cacheKey = `dataset:${args.datasetId}`;
    if (dataset.inputSchema) {
      validator.validate(args.input, dataset.inputSchema, "input", `${cacheKey}:input`);
    }
    if (dataset.groundTruthSchema && args.groundTruth !== void 0) {
      validator.validate(args.groundTruth, dataset.groundTruthSchema, "groundTruth", `${cacheKey}:output`);
    }
    return this._doAddItem(args);
  }
  /**
   * Update an item in a dataset. Validates changed fields against dataset schemas.
   * Subclasses implement _doUpdateItem which handles SCD-2 versioning internally.
   */
  async updateItem(args) {
    const dataset = await this.getDatasetById({ id: args.datasetId });
    if (!dataset) {
      throw new Error(`Dataset not found: ${args.datasetId}`);
    }
    const validator = getSchemaValidator();
    const cacheKey = `dataset:${args.datasetId}`;
    if (args.input !== void 0 && dataset.inputSchema) {
      validator.validate(args.input, dataset.inputSchema, "input", `${cacheKey}:input`);
    }
    if (args.groundTruth !== void 0 && dataset.groundTruthSchema) {
      validator.validate(args.groundTruth, dataset.groundTruthSchema, "groundTruth", `${cacheKey}:output`);
    }
    return this._doUpdateItem(args);
  }
  /**
   * Delete an item from a dataset. Creates a tombstone row via SCD-2.
   * Subclasses implement _doDeleteItem which handles SCD-2 versioning internally.
   */
  async deleteItem(args) {
    return this._doDeleteItem(args);
  }
  /**
   * Batch insert items to a dataset. Validates all items against dataset schemas,
   * then delegates to subclass which handles SCD-2 versioning internally.
   */
  async batchInsertItems(input) {
    const dataset = await this.getDatasetById({ id: input.datasetId });
    if (!dataset) {
      throw new Error(`Dataset not found: ${input.datasetId}`);
    }
    const validator = getSchemaValidator();
    const cacheKey = `dataset:${input.datasetId}`;
    for (const itemData of input.items) {
      if (dataset.inputSchema) {
        validator.validate(itemData.input, dataset.inputSchema, "input", `${cacheKey}:input`);
      }
      if (dataset.groundTruthSchema && itemData.groundTruth !== void 0) {
        validator.validate(itemData.groundTruth, dataset.groundTruthSchema, "groundTruth", `${cacheKey}:output`);
      }
    }
    return this._doBatchInsertItems(input);
  }
  /**
   * Batch delete items from a dataset. Creates tombstone rows via SCD-2.
   * Subclasses implement _doBatchDeleteItems which handles SCD-2 versioning internally.
   */
  async batchDeleteItems(input) {
    const dataset = await this.getDatasetById({ id: input.datasetId });
    if (!dataset) {
      throw new Error(`Dataset not found: ${input.datasetId}`);
    }
    return this._doBatchDeleteItems(input);
  }
};

// src/storage/domains/datasets/inmemory.ts
function toDatasetItem(row) {
  return {
    id: row.id,
    datasetId: row.datasetId,
    datasetVersion: row.datasetVersion,
    input: row.input,
    groundTruth: row.groundTruth,
    metadata: row.metadata,
    createdAt: row.createdAt,
    updatedAt: row.updatedAt
  };
}
var DatasetsInMemory = class extends DatasetsStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.datasets.clear();
    this.db.datasetItems.clear();
    this.db.datasetVersions.clear();
  }
  // Dataset CRUD
  async createDataset(input) {
    const id = crypto.randomUUID();
    const now = /* @__PURE__ */ new Date();
    const dataset = {
      id,
      name: input.name,
      description: input.description,
      metadata: input.metadata,
      inputSchema: input.inputSchema,
      groundTruthSchema: input.groundTruthSchema,
      version: 0,
      createdAt: now,
      updatedAt: now
    };
    this.db.datasets.set(id, dataset);
    return dataset;
  }
  async getDatasetById({ id }) {
    return this.db.datasets.get(id) ?? null;
  }
  async _doUpdateDataset(args) {
    const existing = this.db.datasets.get(args.id);
    if (!existing) {
      throw new Error(`Dataset not found: ${args.id}`);
    }
    const updated = {
      ...existing,
      name: args.name ?? existing.name,
      description: args.description ?? existing.description,
      metadata: args.metadata ?? existing.metadata,
      inputSchema: args.inputSchema !== void 0 ? args.inputSchema : existing.inputSchema,
      groundTruthSchema: args.groundTruthSchema !== void 0 ? args.groundTruthSchema : existing.groundTruthSchema,
      updatedAt: /* @__PURE__ */ new Date()
    };
    this.db.datasets.set(args.id, updated);
    return updated;
  }
  async deleteDataset({ id }) {
    for (const [itemId, rows] of this.db.datasetItems) {
      if (rows.length > 0 && rows[0].datasetId === id) {
        this.db.datasetItems.delete(itemId);
      }
    }
    for (const [vId, v] of this.db.datasetVersions) {
      if (v.datasetId === id) {
        this.db.datasetVersions.delete(vId);
      }
    }
    for (const [expId, exp] of this.db.experiments) {
      if (exp.datasetId === id) {
        this.db.experiments.set(expId, { ...exp, datasetId: null, datasetVersion: null });
      }
    }
    this.db.datasets.delete(id);
  }
  async listDatasets(args) {
    const datasets = Array.from(this.db.datasets.values());
    datasets.sort((a, b) => b.createdAt.getTime() - a.createdAt.getTime());
    const { page, perPage: perPageInput } = args.pagination;
    const perPage = normalizePerPage(perPageInput, 100);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? datasets.length : start + perPage;
    return {
      datasets: datasets.slice(start, end),
      pagination: {
        total: datasets.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : datasets.length > end
      }
    };
  }
  // --- SCD-2 item mutations ---
  async _doAddItem(args) {
    const dataset = this.db.datasets.get(args.datasetId);
    if (!dataset) {
      throw new Error(`Dataset not found: ${args.datasetId}`);
    }
    const newVersion = dataset.version + 1;
    this.db.datasets.set(args.datasetId, { ...dataset, version: newVersion });
    const now = /* @__PURE__ */ new Date();
    const id = crypto.randomUUID();
    const row = {
      id,
      datasetId: args.datasetId,
      datasetVersion: newVersion,
      validTo: null,
      isDeleted: false,
      input: args.input,
      groundTruth: args.groundTruth,
      metadata: args.metadata,
      createdAt: now,
      updatedAt: now
    };
    this.db.datasetItems.set(id, [row]);
    await this.createDatasetVersion(args.datasetId, newVersion);
    return toDatasetItem(row);
  }
  async _doUpdateItem(args) {
    const rows = this.db.datasetItems.get(args.id);
    if (!rows || rows.length === 0) {
      throw new Error(`Item not found: ${args.id}`);
    }
    const currentRow = rows.find((r) => r.validTo === null && !r.isDeleted);
    if (!currentRow) {
      throw new Error(`Item not found: ${args.id}`);
    }
    if (currentRow.datasetId !== args.datasetId) {
      throw new Error(`Item ${args.id} does not belong to dataset ${args.datasetId}`);
    }
    const dataset = this.db.datasets.get(args.datasetId);
    if (!dataset) {
      throw new Error(`Dataset not found: ${args.datasetId}`);
    }
    const newVersion = dataset.version + 1;
    this.db.datasets.set(args.datasetId, { ...dataset, version: newVersion });
    currentRow.validTo = newVersion;
    const now = /* @__PURE__ */ new Date();
    const newRow = {
      id: args.id,
      datasetId: args.datasetId,
      datasetVersion: newVersion,
      validTo: null,
      isDeleted: false,
      input: args.input ?? currentRow.input,
      groundTruth: args.groundTruth ?? currentRow.groundTruth,
      metadata: args.metadata ?? currentRow.metadata,
      createdAt: currentRow.createdAt,
      updatedAt: now
    };
    rows.push(newRow);
    await this.createDatasetVersion(args.datasetId, newVersion);
    return toDatasetItem(newRow);
  }
  async _doDeleteItem({ id, datasetId }) {
    const rows = this.db.datasetItems.get(id);
    if (!rows || rows.length === 0) {
      return;
    }
    const currentRow = rows.find((r) => r.validTo === null && !r.isDeleted);
    if (!currentRow) {
      return;
    }
    if (currentRow.datasetId !== datasetId) {
      throw new Error(`Item ${id} does not belong to dataset ${datasetId}`);
    }
    const dataset = this.db.datasets.get(datasetId);
    if (!dataset) {
      throw new Error(`Dataset not found: ${datasetId}`);
    }
    const newVersion = dataset.version + 1;
    this.db.datasets.set(datasetId, { ...dataset, version: newVersion });
    currentRow.validTo = newVersion;
    const now = /* @__PURE__ */ new Date();
    rows.push({
      id,
      datasetId,
      datasetVersion: newVersion,
      validTo: null,
      isDeleted: true,
      input: currentRow.input,
      groundTruth: currentRow.groundTruth,
      metadata: currentRow.metadata,
      createdAt: currentRow.createdAt,
      updatedAt: now
    });
    await this.createDatasetVersion(datasetId, newVersion);
  }
  // --- SCD-2 queries ---
  async getItemById(args) {
    const rows = this.db.datasetItems.get(args.id);
    if (!rows || rows.length === 0) return null;
    if (args.datasetVersion !== void 0) {
      const row = rows.find((r) => r.datasetVersion === args.datasetVersion && !r.isDeleted);
      return row ? toDatasetItem(row) : null;
    }
    const current = rows.find((r) => r.validTo === null && !r.isDeleted);
    return current ? toDatasetItem(current) : null;
  }
  async getItemsByVersion({ datasetId, version }) {
    const items = [];
    for (const rows of this.db.datasetItems.values()) {
      if (rows.length === 0 || rows[0].datasetId !== datasetId) continue;
      const visible = rows.find(
        (r) => r.datasetVersion <= version && (r.validTo === null || r.validTo > version) && !r.isDeleted
      );
      if (visible) {
        items.push(toDatasetItem(visible));
      }
    }
    items.sort((a, b) => b.createdAt.getTime() - a.createdAt.getTime() || b.id.localeCompare(a.id));
    return items;
  }
  async getItemHistory(itemId) {
    const rows = this.db.datasetItems.get(itemId);
    if (!rows) return [];
    return [...rows].sort((a, b) => b.datasetVersion - a.datasetVersion);
  }
  async listItems(args) {
    let items;
    if (args.version !== void 0) {
      items = await this.getItemsByVersion({ datasetId: args.datasetId, version: args.version });
    } else {
      items = [];
      for (const rows of this.db.datasetItems.values()) {
        if (rows.length === 0 || rows[0].datasetId !== args.datasetId) continue;
        const current = rows.find((r) => r.validTo === null && !r.isDeleted);
        if (current) {
          items.push(toDatasetItem(current));
        }
      }
    }
    if (args.search) {
      const searchLower = args.search.toLowerCase();
      items = items.filter((item) => {
        const inputStr = typeof item.input === "string" ? item.input : JSON.stringify(item.input);
        const outputStr = item.groundTruth ? typeof item.groundTruth === "string" ? item.groundTruth : JSON.stringify(item.groundTruth) : "";
        return inputStr.toLowerCase().includes(searchLower) || outputStr.toLowerCase().includes(searchLower);
      });
    }
    items.sort((a, b) => b.createdAt.getTime() - a.createdAt.getTime() || b.id.localeCompare(a.id));
    const { page, perPage: perPageInput } = args.pagination;
    const perPage = normalizePerPage(perPageInput, 100);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? items.length : start + perPage;
    return {
      items: items.slice(start, end),
      pagination: {
        total: items.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : items.length > end
      }
    };
  }
  // --- Dataset version methods ---
  async createDatasetVersion(datasetId, version) {
    const id = crypto.randomUUID();
    const dsVersion = {
      id,
      datasetId,
      version,
      createdAt: /* @__PURE__ */ new Date()
    };
    this.db.datasetVersions.set(id, dsVersion);
    return dsVersion;
  }
  async listDatasetVersions(input) {
    const versions = [];
    for (const v of this.db.datasetVersions.values()) {
      if (v.datasetId === input.datasetId) {
        versions.push(v);
      }
    }
    versions.sort((a, b) => b.version - a.version);
    const { page, perPage: perPageInput } = input.pagination;
    const perPage = normalizePerPage(perPageInput, 100);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? versions.length : start + perPage;
    return {
      versions: versions.slice(start, end),
      pagination: {
        total: versions.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : versions.length > end
      }
    };
  }
  // --- Bulk operations (SCD-2 internally) ---
  async _doBatchInsertItems(input) {
    const dataset = this.db.datasets.get(input.datasetId);
    if (!dataset) {
      throw new Error(`Dataset not found: ${input.datasetId}`);
    }
    const newVersion = dataset.version + 1;
    this.db.datasets.set(input.datasetId, { ...dataset, version: newVersion });
    const now = /* @__PURE__ */ new Date();
    const items = [];
    for (const itemInput of input.items) {
      const id = crypto.randomUUID();
      const row = {
        id,
        datasetId: input.datasetId,
        datasetVersion: newVersion,
        validTo: null,
        isDeleted: false,
        input: itemInput.input,
        groundTruth: itemInput.groundTruth,
        metadata: itemInput.metadata,
        createdAt: now,
        updatedAt: now
      };
      this.db.datasetItems.set(id, [row]);
      items.push(toDatasetItem(row));
    }
    await this.createDatasetVersion(input.datasetId, newVersion);
    return items;
  }
  async _doBatchDeleteItems(input) {
    const dataset = this.db.datasets.get(input.datasetId);
    if (!dataset) {
      throw new Error(`Dataset not found: ${input.datasetId}`);
    }
    const newVersion = dataset.version + 1;
    this.db.datasets.set(input.datasetId, { ...dataset, version: newVersion });
    const now = /* @__PURE__ */ new Date();
    for (const itemId of input.itemIds) {
      const rows = this.db.datasetItems.get(itemId);
      if (!rows) continue;
      const currentRow = rows.find((r) => r.validTo === null && !r.isDeleted);
      if (!currentRow || currentRow.datasetId !== input.datasetId) continue;
      currentRow.validTo = newVersion;
      rows.push({
        id: itemId,
        datasetId: input.datasetId,
        datasetVersion: newVersion,
        validTo: null,
        isDeleted: true,
        input: currentRow.input,
        groundTruth: currentRow.groundTruth,
        metadata: currentRow.metadata,
        createdAt: currentRow.createdAt,
        updatedAt: now
      });
    }
    await this.createDatasetVersion(input.datasetId, newVersion);
  }
};

// src/storage/domains/experiments/base.ts
var ExperimentsStorage = class extends StorageDomain {
  constructor() {
    super({
      component: "STORAGE",
      name: "EXPERIMENTS"
    });
  }
  async dangerouslyClearAll() {
  }
};

// src/storage/domains/experiments/inmemory.ts
var ExperimentsInMemory = class extends ExperimentsStorage {
  db;
  constructor({ db }) {
    super();
    this.db = db;
  }
  async dangerouslyClearAll() {
    this.db.experiments.clear();
    this.db.experimentResults.clear();
  }
  // Experiment lifecycle
  async createExperiment(input) {
    const now = /* @__PURE__ */ new Date();
    const experiment = {
      id: input.id ?? crypto.randomUUID(),
      datasetId: input.datasetId,
      datasetVersion: input.datasetVersion,
      targetType: input.targetType,
      targetId: input.targetId,
      name: input.name,
      description: input.description,
      metadata: input.metadata,
      status: "pending",
      totalItems: input.totalItems,
      succeededCount: 0,
      failedCount: 0,
      skippedCount: 0,
      startedAt: null,
      completedAt: null,
      createdAt: now,
      updatedAt: now
    };
    this.db.experiments.set(experiment.id, experiment);
    return experiment;
  }
  async updateExperiment(input) {
    const existing = this.db.experiments.get(input.id);
    if (!existing) {
      throw new Error(`Experiment not found: ${input.id}`);
    }
    const updated = {
      ...existing,
      status: input.status ?? existing.status,
      succeededCount: input.succeededCount ?? existing.succeededCount,
      failedCount: input.failedCount ?? existing.failedCount,
      skippedCount: input.skippedCount ?? existing.skippedCount,
      startedAt: input.startedAt ?? existing.startedAt,
      completedAt: input.completedAt ?? existing.completedAt,
      name: input.name ?? existing.name,
      description: input.description ?? existing.description,
      metadata: input.metadata ?? existing.metadata,
      updatedAt: /* @__PURE__ */ new Date()
    };
    this.db.experiments.set(input.id, updated);
    return updated;
  }
  async getExperimentById(args) {
    return this.db.experiments.get(args.id) ?? null;
  }
  async listExperiments(args) {
    let experiments = Array.from(this.db.experiments.values());
    if (args.datasetId) {
      experiments = experiments.filter((r) => r.datasetId === args.datasetId);
    }
    experiments.sort((a, b) => b.createdAt.getTime() - a.createdAt.getTime());
    const { page, perPage: perPageInput } = args.pagination;
    const perPage = normalizePerPage(perPageInput, 100);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? experiments.length : start + perPage;
    return {
      experiments: experiments.slice(start, end),
      pagination: {
        total: experiments.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : experiments.length > end
      }
    };
  }
  async deleteExperiment(args) {
    this.db.experiments.delete(args.id);
    for (const [resultId, result] of this.db.experimentResults) {
      if (result.experimentId === args.id) {
        this.db.experimentResults.delete(resultId);
      }
    }
  }
  // Results (per-item)
  async addExperimentResult(input) {
    const now = /* @__PURE__ */ new Date();
    const result = {
      id: input.id ?? crypto.randomUUID(),
      experimentId: input.experimentId,
      itemId: input.itemId,
      itemDatasetVersion: input.itemDatasetVersion,
      input: input.input,
      output: input.output,
      groundTruth: input.groundTruth,
      error: input.error,
      startedAt: input.startedAt,
      completedAt: input.completedAt,
      retryCount: input.retryCount,
      traceId: input.traceId ?? null,
      createdAt: now
    };
    this.db.experimentResults.set(result.id, result);
    return result;
  }
  async getExperimentResultById(args) {
    return this.db.experimentResults.get(args.id) ?? null;
  }
  async listExperimentResults(args) {
    let results = Array.from(this.db.experimentResults.values()).filter((r) => r.experimentId === args.experimentId);
    results.sort((a, b) => a.startedAt.getTime() - b.startedAt.getTime());
    const { page, perPage: perPageInput } = args.pagination;
    const perPage = normalizePerPage(perPageInput, 100);
    const { offset: start, perPage: perPageForResponse } = calculatePagination(page, perPageInput, perPage);
    const end = perPageInput === false ? results.length : start + perPage;
    return {
      results: results.slice(start, end),
      pagination: {
        total: results.length,
        page,
        perPage: perPageForResponse,
        hasMore: perPageInput === false ? false : results.length > end
      }
    };
  }
  async deleteExperimentResults(args) {
    for (const [resultId, result] of this.db.experimentResults) {
      if (result.experimentId === args.experimentId) {
        this.db.experimentResults.delete(resultId);
      }
    }
  }
};

export { AgentsStorage, DatasetsInMemory, DatasetsStorage, ExperimentsInMemory, ExperimentsStorage, InMemoryAgentsStorage, InMemoryDB, InMemoryMCPClientsStorage, InMemoryMemory, InMemoryPromptBlocksStorage, InMemoryScorerDefinitionsStorage, InMemoryStore, MCPClientsStorage, MastraCompositeStore, MastraStorage, MemoryStorage, MockStore, ObservabilityInMemory, ObservabilityStorage, PromptBlocksStorage, SchemaUpdateValidationError, SchemaValidationError, SchemaValidator, ScorerDefinitionsStorage, ScoresInMemory, ScoresStorage, StorageDomain, StoreOperations, StoreOperationsInMemory, VersionedStorageDomain, WorkflowsInMemory, WorkflowsStorage, calculatePagination, createPendingMarker, createStorageErrorId, createStoreErrorId, createValidator, createVectorErrorId, ensureDate, filterByDateRange, getDefaultValue, getSchemaValidator, getSqlType, jsonValueEquals, normalizePerPage, safelyParseJSON, serializeDate, transformRow, transformScoreRow };
//# sourceMappingURL=chunk-7NKUSQEV.js.map
//# sourceMappingURL=chunk-7NKUSQEV.js.map